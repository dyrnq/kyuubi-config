[
  {
    "Key": "jobmanager.rpc.address",
    "Default": "(none)",
    "Type": "String",
    "Description": "The config parameter defining the network address to connect to for communication with the job manager. This value is only interpreted in setups where a single JobManager with static name or address exists (simple standalone setups, or container setups with dynamic service name resolution). It is not used in many high-availability setups, when a leader-election service (like ZooKeeper) is used to elect and discover the JobManager leader from potentially multiple standby JobManagers."
  },
  {
    "Key": "jobmanager.rpc.port",
    "Default": "6123",
    "Type": "Integer",
    "Description": "The config parameter defining the network port to connect to for communication with the job manager. Like jobmanager.rpc.address, this value is only interpreted in setups where a single JobManager with static name/address and port exists (simple standalone setups, or container setups with dynamic service name resolution). This config option is not used in many high-availability setups, when a leader-election service (like ZooKeeper) is used to elect and discover the JobManager leader from potentially multiple standby JobManagers."
  },
  {
    "Key": "metrics.internal.query-service.port",
    "Default": "\"0\"",
    "Type": "String",
    "Description": "The port range used for Flink\u0027s internal metric query service. Accepts a list of ports (“50100,50101”), ranges(“50100-50200”) or a combination of both. It is recommended to set a range of ports to avoid collisions when multiple Flink components are running on the same machine. Per default Flink will pick a random port."
  },
  {
    "Key": "rest.address",
    "Default": "(none)",
    "Type": "String",
    "Description": "The address that should be used by clients to connect to the server. Attention: This option is respected only if the high-availability configuration is NONE."
  },
  {
    "Key": "rest.bind-address",
    "Default": "(none)",
    "Type": "String",
    "Description": "The address that the server binds itself."
  },
  {
    "Key": "rest.bind-port",
    "Default": "\"8081\"",
    "Type": "String",
    "Description": "The port that the server binds itself. Accepts a list of ports (“50100,50101”), ranges (“50100-50200”) or a combination of both. It is recommended to set a range of ports to avoid collisions when multiple Rest servers are running on the same machine."
  },
  {
    "Key": "rest.port",
    "Default": "8081",
    "Type": "Integer",
    "Description": "The port that the client connects to. If rest.bind-port has not been specified, then the REST server will bind to this port. Attention: This option is respected only if the high-availability configuration is NONE."
  },
  {
    "Key": "taskmanager.data.port",
    "Default": "0",
    "Type": "Integer",
    "Description": "The task manager’s external port used for data exchange operations."
  },
  {
    "Key": "taskmanager.host",
    "Default": "(none)",
    "Type": "String",
    "Description": "The external address of the network interface where the TaskManager is exposed. Because different TaskManagers need different values for this option, usually it is specified in an additional non-shared TaskManager-specific config file."
  },
  {
    "Key": "taskmanager.rpc.port",
    "Default": "\"0\"",
    "Type": "String",
    "Description": "The external RPC port where the TaskManager is exposed. Accepts a list of ports (“50100,50101”), ranges (“50100-50200”) or a combination of both. It is recommended to set a range of ports to avoid collisions when multiple TaskManagers are running on the same machine."
  },
  {
    "Key": "restart-strategy",
    "Default": "(none)",
    "Type": "String",
    "Description": "Defines the restart strategy to use in case of job failures. Accepted values are: none, off, disable: No restart strategy. fixeddelay, fixed-delay: Fixed delay restart strategy. More details can be found here. failurerate, failure-rate: Failure rate restart strategy. More details can be found here. exponentialdelay, exponential-delay: Exponential delay restart strategy. More details can be found here. If checkpointing is disabled, the default value is none. If checkpointing is enabled, the default value is fixed-delay with Integer.MAX_VALUE restart attempts and \u00271 s\u0027 delay."
  },
  {
    "Key": "restart-strategy.fixed-delay.attempts",
    "Default": "1",
    "Type": "Integer",
    "Description": "The number of times that Flink retries the execution before the job is declared as failed if restart-strategy has been set to fixed-delay."
  },
  {
    "Key": "restart-strategy.fixed-delay.delay",
    "Default": "1 s",
    "Type": "Duration",
    "Description": "Delay between two consecutive restart attempts if restart-strategy has been set to fixed-delay. Delaying the retries can be helpful when the program interacts with external systems where for example connections or pending transactions should reach a timeout before re-execution is attempted. It can be specified using notation: \"1 min\", \"20 s\""
  },
  {
    "Key": "restart-strategy.failure-rate.delay",
    "Default": "1 s",
    "Type": "Duration",
    "Description": "Delay between two consecutive restart attempts if restart-strategy has been set to failure-rate. It can be specified using notation: \"1 min\", \"20 s\""
  },
  {
    "Key": "restart-strategy.failure-rate.failure-rate-interval",
    "Default": "1 min",
    "Type": "Duration",
    "Description": "Time interval for measuring failure rate if restart-strategy has been set to failure-rate. It can be specified using notation: \"1 min\", \"20 s\""
  },
  {
    "Key": "restart-strategy.failure-rate.max-failures-per-interval",
    "Default": "1",
    "Type": "Integer",
    "Description": "Maximum number of restarts in given time interval before failing a job if restart-strategy has been set to failure-rate."
  },
  {
    "Key": "state.backend",
    "Default": "(none)",
    "Type": "String",
    "Description": "The state backend to be used to store state. The implementation can be specified either via their shortcut name, or via the class name of a StateBackendFactory. If a factory is specified it is instantiated via its zero argument constructor and its StateBackendFactory#createFromConfig(ReadableConfig, ClassLoader) method is called. Recognized shortcut names are \u0027hashmap\u0027 and \u0027rocksdb\u0027."
  },
  {
    "Key": "state.checkpoint-storage",
    "Default": "(none)",
    "Type": "String",
    "Description": "The checkpoint storage implementation to be used to checkpoint state. The implementation can be specified either via their shortcut name, or via the class name of a CheckpointStorageFactory. If a factory is specified it is instantiated via its zero argument constructor and its CheckpointStorageFactory#createFromConfig(ReadableConfig, ClassLoader) method is called. Recognized shortcut names are \u0027jobmanager\u0027 and \u0027filesystem\u0027."
  },
  {
    "Key": "state.checkpoints.dir",
    "Default": "(none)",
    "Type": "String",
    "Description": "The default directory used for storing the data files and meta data of checkpoints in a Flink supported filesystem. The storage path must be accessible from all participating processes/nodes(i.e. all TaskManagers and JobManagers)."
  },
  {
    "Key": "state.savepoints.dir",
    "Default": "(none)",
    "Type": "String",
    "Description": "The default directory for savepoints. Used by the state backends that write savepoints to file systems (HashMapStateBackend, EmbeddedRocksDBStateBackend)."
  },
  {
    "Key": "state.backend.incremental",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Option whether the state backend should create incremental checkpoints, if possible. For an incremental checkpoint, only a diff from the previous checkpoint is stored, rather than the complete checkpoint state. Once enabled, the state size shown in web UI or fetched from rest API only represents the delta checkpoint size instead of full checkpoint size. Some state backends may not support incremental checkpoints and ignore this option."
  },
  {
    "Key": "state.backend.local-recovery",
    "Default": "false",
    "Type": "Boolean",
    "Description": "This option configures local recovery for this state backend. By default, local recovery is deactivated. Local recovery currently only covers keyed state backends. Currently, the MemoryStateBackend does not support local recovery and ignores this option."
  },
  {
    "Key": "state.checkpoints.num-retained",
    "Default": "1",
    "Type": "Integer",
    "Description": "The maximum number of completed checkpoints to retain."
  },
  {
    "Key": "taskmanager.state.local.root-dirs",
    "Default": "(none)",
    "Type": "String",
    "Description": "The config parameter defining the root directories for storing file-based state for local recovery. Local recovery currently only covers keyed state backends. Currently, MemoryStateBackend does not support local recovery and ignore this option"
  },
  {
    "Key": "high-availability",
    "Default": "\"NONE\"",
    "Type": "String",
    "Description": "Defines high-availability mode used for the cluster execution. To enable high-availability, set this mode to \"ZOOKEEPER\" or specify FQN of factory class."
  },
  {
    "Key": "high-availability.cluster-id",
    "Default": "\"/default\"",
    "Type": "String",
    "Description": "The ID of the Flink cluster, used to separate multiple Flink clusters from each other. Needs to be set for standalone clusters but is automatically inferred in YARN and Mesos."
  },
  {
    "Key": "high-availability.storageDir",
    "Default": "(none)",
    "Type": "String",
    "Description": "File system path (URI) where Flink persists metadata in high-availability setups."
  },
  {
    "Key": "high-availability.zookeeper.path.root",
    "Default": "\"/flink\"",
    "Type": "String",
    "Description": "The root path under which Flink stores its entries in ZooKeeper."
  },
  {
    "Key": "high-availability.zookeeper.quorum",
    "Default": "(none)",
    "Type": "String",
    "Description": "The ZooKeeper quorum to use, when running Flink in a high-availability mode with ZooKeeper."
  },
  {
    "Key": "jobmanager.memory.enable-jvm-direct-memory-limit",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Whether to enable the JVM direct memory limit of the JobManager process (-XX:MaxDirectMemorySize). The limit will be set to the value of \u0027jobmanager.memory.off-heap.size\u0027 option."
  },
  {
    "Key": "jobmanager.memory.flink.size",
    "Default": "(none)",
    "Type": "MemorySize",
    "Description": "Total Flink Memory size for the JobManager. This includes all the memory that a JobManager consumes, except for JVM Metaspace and JVM Overhead. It consists of JVM Heap Memory and Off-heap Memory. See also \u0027jobmanager.memory.process.size\u0027 for total process memory size configuration."
  },
  {
    "Key": "jobmanager.memory.heap.size",
    "Default": "(none)",
    "Type": "MemorySize",
    "Description": "JVM Heap Memory size for JobManager. The minimum recommended JVM Heap size is 128.000mb (134217728 bytes)."
  },
  {
    "Key": "jobmanager.memory.jvm-metaspace.size",
    "Default": "256 mb",
    "Type": "MemorySize",
    "Description": "JVM Metaspace Size for the JobManager."
  },
  {
    "Key": "jobmanager.memory.jvm-overhead.fraction",
    "Default": "0.1",
    "Type": "Float",
    "Description": "Fraction of Total Process Memory to be reserved for JVM Overhead. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less or greater than the configured min or max size, the min or max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min and max size to the same value."
  },
  {
    "Key": "jobmanager.memory.jvm-overhead.max",
    "Default": "1 gb",
    "Type": "MemorySize",
    "Description": "Max JVM Overhead size for the JobManager. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less or greater than the configured min or max size, the min or max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min and max size to the same value."
  },
  {
    "Key": "jobmanager.memory.jvm-overhead.min",
    "Default": "192 mb",
    "Type": "MemorySize",
    "Description": "Min JVM Overhead size for the JobManager. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less or greater than the configured min or max size, the min or max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min and max size to the same value."
  },
  {
    "Key": "jobmanager.memory.off-heap.size",
    "Default": "128 mb",
    "Type": "MemorySize",
    "Description": "Off-heap Memory size for JobManager. This option covers all off-heap memory usage including direct and native memory allocation. The JVM direct memory limit of the JobManager process (-XX:MaxDirectMemorySize) will be set to this value if the limit is enabled by \u0027jobmanager.memory.enable-jvm-direct-memory-limit\u0027."
  },
  {
    "Key": "jobmanager.memory.process.size",
    "Default": "(none)",
    "Type": "MemorySize",
    "Description": "Total Process Memory size for the JobManager. This includes all the memory that a JobManager JVM process consumes, consisting of Total Flink Memory, JVM Metaspace, and JVM Overhead. In containerized setups, this should be set to the container memory. See also \u0027jobmanager.memory.flink.size\u0027 for Total Flink Memory size configuration."
  },
  {
    "Key": "taskmanager.memory.flink.size",
    "Default": "(none)",
    "Type": "MemorySize",
    "Description": "Total Flink Memory size for the TaskExecutors. This includes all the memory that a TaskExecutor consumes, except for JVM Metaspace and JVM Overhead. It consists of Framework Heap Memory, Task Heap Memory, Task Off-Heap Memory, Managed Memory, and Network Memory. See also \u0027taskmanager.memory.process.size\u0027 for total process memory size configuration."
  },
  {
    "Key": "taskmanager.memory.framework.heap.size",
    "Default": "128 mb",
    "Type": "MemorySize",
    "Description": "Framework Heap Memory size for TaskExecutors. This is the size of JVM heap memory reserved for TaskExecutor framework, which will not be allocated to task slots."
  },
  {
    "Key": "taskmanager.memory.framework.off-heap.batch-shuffle.size",
    "Default": "32 mb",
    "Type": "MemorySize",
    "Description": "Size of memory used by blocking shuffle for shuffle data read (currently only used by sort-merge shuffle). Notes: 1) The memory is cut from \u0027taskmanager.memory.framework.off-heap.size\u0027 so must be smaller than that, which means you may also need to increase \u0027taskmanager.memory.framework.off-heap.size\u0027 after you increase this config value; 2) This memory size can influence the shuffle performance and you can increase this config value for large-scale batch jobs (for example, to 128M or 256M)."
  },
  {
    "Key": "taskmanager.memory.framework.off-heap.size",
    "Default": "128 mb",
    "Type": "MemorySize",
    "Description": "Framework Off-Heap Memory size for TaskExecutors. This is the size of off-heap memory (JVM direct memory and native memory) reserved for TaskExecutor framework, which will not be allocated to task slots. The configured value will be fully counted when Flink calculates the JVM max direct memory size parameter."
  },
  {
    "Key": "taskmanager.memory.jvm-metaspace.size",
    "Default": "256 mb",
    "Type": "MemorySize",
    "Description": "JVM Metaspace Size for the TaskExecutors."
  },
  {
    "Key": "taskmanager.memory.jvm-overhead.fraction",
    "Default": "0.1",
    "Type": "Float",
    "Description": "Fraction of Total Process Memory to be reserved for JVM Overhead. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less/greater than the configured min/max size, the min/max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min/max size to the same value."
  },
  {
    "Key": "taskmanager.memory.jvm-overhead.max",
    "Default": "1 gb",
    "Type": "MemorySize",
    "Description": "Max JVM Overhead size for the TaskExecutors. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less/greater than the configured min/max size, the min/max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min/max size to the same value."
  },
  {
    "Key": "taskmanager.memory.jvm-overhead.min",
    "Default": "192 mb",
    "Type": "MemorySize",
    "Description": "Min JVM Overhead size for the TaskExecutors. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less/greater than the configured min/max size, the min/max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min/max size to the same value."
  },
  {
    "Key": "taskmanager.memory.managed.consumer-weights",
    "Default": "OPERATOR:70,STATE_BACKEND:70,PYTHON:30",
    "Type": "Map",
    "Description": "Managed memory weights for different kinds of consumers. A slot’s managed memory is shared by all kinds of consumers it contains, proportionally to the kinds’ weights and regardless of the number of consumers from each kind. Currently supported kinds of consumers are OPERATOR (for built-in algorithms), STATE_BACKEND (for RocksDB state backend) and PYTHON (for Python processes)."
  },
  {
    "Key": "taskmanager.memory.managed.fraction",
    "Default": "0.4",
    "Type": "Float",
    "Description": "Fraction of Total Flink Memory to be used as Managed Memory, if Managed Memory size is not explicitly specified."
  },
  {
    "Key": "taskmanager.memory.managed.size",
    "Default": "(none)",
    "Type": "MemorySize",
    "Description": "Managed Memory size for TaskExecutors. This is the size of off-heap memory managed by the memory manager, reserved for sorting, hash tables, caching of intermediate results and RocksDB state backend. Memory consumers can either allocate memory from the memory manager in the form of MemorySegments, or reserve bytes from the memory manager and keep their memory usage within that boundary. If unspecified, it will be derived to make up the configured fraction of the Total Flink Memory."
  },
  {
    "Key": "taskmanager.memory.network.fraction",
    "Default": "0.1",
    "Type": "Float",
    "Description": "Fraction of Total Flink Memory to be used as Network Memory. Network Memory is off-heap memory reserved for ShuffleEnvironment (e.g., network buffers). Network Memory size is derived to make up the configured fraction of the Total Flink Memory. If the derived size is less/greater than the configured min/max size, the min/max size will be used. The exact size of Network Memory can be explicitly specified by setting the min/max size to the same value."
  },
  {
    "Key": "taskmanager.memory.network.max",
    "Default": "1 gb",
    "Type": "MemorySize",
    "Description": "Max Network Memory size for TaskExecutors. Network Memory is off-heap memory reserved for ShuffleEnvironment (e.g., network buffers). Network Memory size is derived to make up the configured fraction of the Total Flink Memory. If the derived size is less/greater than the configured min/max size, the min/max size will be used. The exact size of Network Memory can be explicitly specified by setting the min/max to the same value."
  },
  {
    "Key": "taskmanager.memory.network.min",
    "Default": "64 mb",
    "Type": "MemorySize",
    "Description": "Min Network Memory size for TaskExecutors. Network Memory is off-heap memory reserved for ShuffleEnvironment (e.g., network buffers). Network Memory size is derived to make up the configured fraction of the Total Flink Memory. If the derived size is less/greater than the configured min/max size, the min/max size will be used. The exact size of Network Memory can be explicitly specified by setting the min/max to the same value."
  },
  {
    "Key": "taskmanager.memory.process.size",
    "Default": "(none)",
    "Type": "MemorySize",
    "Description": "Total Process Memory size for the TaskExecutors. This includes all the memory that a TaskExecutor consumes, consisting of Total Flink Memory, JVM Metaspace, and JVM Overhead. On containerized setups, this should be set to the container memory. See also \u0027taskmanager.memory.flink.size\u0027 for total Flink memory size configuration."
  },
  {
    "Key": "taskmanager.memory.task.heap.size",
    "Default": "(none)",
    "Type": "MemorySize",
    "Description": "Task Heap Memory size for TaskExecutors. This is the size of JVM heap memory reserved for tasks. If not specified, it will be derived as Total Flink Memory minus Framework Heap Memory, Framework Off-Heap Memory, Task Off-Heap Memory, Managed Memory and Network Memory."
  },
  {
    "Key": "taskmanager.memory.task.off-heap.size",
    "Default": "0 bytes",
    "Type": "MemorySize",
    "Description": "Task Off-Heap Memory size for TaskExecutors. This is the size of off heap memory (JVM direct memory and native memory) reserved for tasks. The configured value will be fully counted when Flink calculates the JVM max direct memory size parameter."
  },
  {
    "Key": "fs.allowed-fallback-filesystems",
    "Default": "(none)",
    "Type": "String",
    "Description": "A (semicolon-separated) list of file schemes, for which Hadoop can be used instead of an appropriate Flink plugin. (example: s3;wasb)"
  },
  {
    "Key": "fs.default-scheme",
    "Default": "(none)",
    "Type": "String",
    "Description": "The default filesystem scheme, used for paths that do not declare a scheme explicitly. May contain an authority, e.g. host:port in case of an HDFS NameNode."
  },
  {
    "Key": "io.tmp.dirs",
    "Default": "\u0027LOCAL_DIRS\u0027 on Yarn. \u0027_FLINK_TMP_DIR\u0027 on Mesos. System.getProperty(\"java.io.tmpdir\") in standalone.",
    "Type": "String",
    "Description": "Directories for temporary files, separated by\",\", \"|\", or the system\u0027s java.io.File.pathSeparator."
  },
  {
    "Key": "security.ssl.algorithms",
    "Default": "\"TLS_RSA_WITH_AES_128_CBC_SHA\"",
    "Type": "String",
    "Description": "The comma separated list of standard SSL algorithms to be supported. Read more here"
  },
  {
    "Key": "security.ssl.internal.cert.fingerprint",
    "Default": "(none)",
    "Type": "String",
    "Description": "The sha1 fingerprint of the internal certificate. This further protects the internal communication to present the exact certificate used by Flink.This is necessary where one cannot use private CA(self signed) or there is internal firm wide CA is required"
  },
  {
    "Key": "security.ssl.internal.enabled",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Turns on SSL for internal network communication. Optionally, specific components may override this through their own settings (rpc, data transport, REST, etc)."
  },
  {
    "Key": "security.ssl.internal.key-password",
    "Default": "(none)",
    "Type": "String",
    "Description": "The secret to decrypt the key in the keystore for Flink\u0027s internal endpoints (rpc, data transport, blob server)."
  },
  {
    "Key": "security.ssl.internal.keystore",
    "Default": "(none)",
    "Type": "String",
    "Description": "The Java keystore file with SSL Key and Certificate, to be used Flink\u0027s internal endpoints (rpc, data transport, blob server)."
  },
  {
    "Key": "security.ssl.internal.keystore-password",
    "Default": "(none)",
    "Type": "String",
    "Description": "The secret to decrypt the keystore file for Flink\u0027s for Flink\u0027s internal endpoints (rpc, data transport, blob server)."
  },
  {
    "Key": "security.ssl.internal.truststore",
    "Default": "(none)",
    "Type": "String",
    "Description": "The truststore file containing the public CA certificates to verify the peer for Flink\u0027s internal endpoints (rpc, data transport, blob server)."
  },
  {
    "Key": "security.ssl.internal.truststore-password",
    "Default": "(none)",
    "Type": "String",
    "Description": "The password to decrypt the truststore for Flink\u0027s internal endpoints (rpc, data transport, blob server)."
  },
  {
    "Key": "security.ssl.protocol",
    "Default": "\"TLSv1.2\"",
    "Type": "String",
    "Description": "The SSL protocol version to be supported for the ssl transport. Note that it doesn’t support comma separated list."
  },
  {
    "Key": "security.ssl.rest.authentication-enabled",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Turns on mutual SSL authentication for external communication via the REST endpoints."
  },
  {
    "Key": "security.ssl.rest.cert.fingerprint",
    "Default": "(none)",
    "Type": "String",
    "Description": "The sha1 fingerprint of the rest certificate. This further protects the rest REST endpoints to present certificate which is only used by proxy serverThis is necessary where once uses public CA or internal firm wide CA"
  },
  {
    "Key": "security.ssl.rest.enabled",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Turns on SSL for external communication via the REST endpoints."
  },
  {
    "Key": "security.ssl.rest.key-password",
    "Default": "(none)",
    "Type": "String",
    "Description": "The secret to decrypt the key in the keystore for Flink\u0027s external REST endpoints."
  },
  {
    "Key": "security.ssl.rest.keystore",
    "Default": "(none)",
    "Type": "String",
    "Description": "The Java keystore file with SSL Key and Certificate, to be used Flink\u0027s external REST endpoints."
  },
  {
    "Key": "security.ssl.rest.keystore-password",
    "Default": "(none)",
    "Type": "String",
    "Description": "The secret to decrypt the keystore file for Flink\u0027s for Flink\u0027s external REST endpoints."
  },
  {
    "Key": "security.ssl.rest.truststore",
    "Default": "(none)",
    "Type": "String",
    "Description": "The truststore file containing the public CA certificates to verify the peer for Flink\u0027s external REST endpoints."
  },
  {
    "Key": "security.ssl.rest.truststore-password",
    "Default": "(none)",
    "Type": "String",
    "Description": "The password to decrypt the truststore for Flink\u0027s external REST endpoints."
  },
  {
    "Key": "security.ssl.verify-hostname",
    "Default": "true",
    "Type": "Boolean",
    "Description": "Flag to enable peer’s hostname verification during ssl handshake."
  },
  {
    "Key": "zookeeper.sasl.disable",
    "Default": "false",
    "Type": "Boolean",
    "Description": ""
  },
  {
    "Key": "zookeeper.sasl.login-context-name",
    "Default": "\"Client\"",
    "Type": "String",
    "Description": ""
  },
  {
    "Key": "zookeeper.sasl.service-name",
    "Default": "\"zookeeper\"",
    "Type": "String",
    "Description": ""
  },
  {
    "Key": "security.kerberos.login.contexts",
    "Default": "(none)",
    "Type": "String",
    "Description": "A comma-separated list of login contexts to provide the Kerberos credentials to (for example, `Client,KafkaClient` to use the credentials for ZooKeeper authentication and for Kafka authentication)"
  },
  {
    "Key": "security.kerberos.login.keytab",
    "Default": "(none)",
    "Type": "String",
    "Description": "Absolute path to a Kerberos keytab file that contains the user credentials."
  },
  {
    "Key": "security.kerberos.login.principal",
    "Default": "(none)",
    "Type": "String",
    "Description": "Kerberos principal name associated with the keytab."
  },
  {
    "Key": "security.kerberos.login.use-ticket-cache",
    "Default": "true",
    "Type": "Boolean",
    "Description": "Indicates whether to read from your Kerberos ticket cache."
  },
  {
    "Key": "external-resource.\u003cresource_name\u003e.yarn.config-key",
    "Default": "(none)",
    "Type": "String",
    "Description": "If configured, Flink will add this key to the resource profile of container request to Yarn. The value will be set to the value of external-resource.\u003cresource_name\u003e.amount."
  },
  {
    "Key": "flink.hadoop.\u003ckey\u003e",
    "Default": "(none)",
    "Type": "String",
    "Description": "A general option to probe Hadoop configuration through prefix \u0027flink.hadoop.\u0027. Flink will remove the prefix to get \u003ckey\u003e (from core-default.xml and hdfs-default.xml) then set the \u003ckey\u003e and value to Hadoop configuration. For example, flink.hadoop.dfs.replication\u003d5 in Flink configuration and convert to dfs.replication\u003d5 in Hadoop configuration."
  },
  {
    "Key": "flink.yarn.\u003ckey\u003e",
    "Default": "(none)",
    "Type": "String",
    "Description": "A general option to probe Yarn configuration through prefix \u0027flink.yarn.\u0027. Flink will remove the prefix \u0027flink.\u0027 to get yarn.\u003ckey\u003e (from yarn-default.xml) then set the yarn.\u003ckey\u003e and value to Yarn configuration. For example, flink.yarn.resourcemanager.container.liveness-monitor.interval-ms\u003d300000 in Flink configuration and convert to yarn.resourcemanager.container.liveness-monitor.interval-ms\u003d300000 in Yarn configuration."
  },
  {
    "Key": "yarn.application-attempt-failures-validity-interval",
    "Default": "10000",
    "Type": "Long",
    "Description": "Time window in milliseconds which defines the number of application attempt failures when restarting the AM. Failures which fall outside of this window are not being considered. Set this value to -1 in order to count globally. See here for more information."
  },
  {
    "Key": "yarn.application-attempts",
    "Default": "(none)",
    "Type": "String",
    "Description": "Number of ApplicationMaster restarts. By default, the value will be set to 1. If high availability is enabled, then the default value will be 2. The restart number is also limited by YARN (configured via yarn.resourcemanager.am.max-attempts). Note that that the entire Flink cluster will restart and the YARN Client will lose the connection."
  },
  {
    "Key": "yarn.application-master.port",
    "Default": "\"0\"",
    "Type": "String",
    "Description": "With this configuration option, users can specify a port, a range of ports or a list of ports for the Application Master (and JobManager) RPC port. By default we recommend using the default value (0) to let the operating system choose an appropriate port. In particular when multiple AMs are running on the same physical host, fixed port assignments prevent the AM from starting. For example when running Flink on YARN on an environment with a restrictive firewall, this option allows specifying a range of allowed ports."
  },
  {
    "Key": "yarn.application.id",
    "Default": "(none)",
    "Type": "String",
    "Description": "The YARN application id of the running yarn cluster. This is the YARN cluster where the pipeline is going to be executed."
  },
  {
    "Key": "yarn.application.name",
    "Default": "(none)",
    "Type": "String",
    "Description": "A custom name for your YARN application."
  },
  {
    "Key": "yarn.application.node-label",
    "Default": "(none)",
    "Type": "String",
    "Description": "Specify YARN node label for the YARN application."
  },
  {
    "Key": "yarn.application.priority",
    "Default": "-1",
    "Type": "Integer",
    "Description": "A non-negative integer indicating the priority for submitting a Flink YARN application. It will only take effect if YARN priority scheduling setting is enabled. Larger integer corresponds with higher priority. If priority is negative or set to \u0027-1\u0027(default), Flink will unset yarn priority setting and use cluster default priority. Please refer to YARN\u0027s official documentation for specific settings required to enable priority scheduling for the targeted YARN version."
  },
  {
    "Key": "yarn.application.queue",
    "Default": "(none)",
    "Type": "String",
    "Description": "The YARN queue on which to put the current pipeline."
  },
  {
    "Key": "yarn.application.type",
    "Default": "(none)",
    "Type": "String",
    "Description": "A custom type for your YARN application.."
  },
  {
    "Key": "yarn.appmaster.vcores",
    "Default": "1",
    "Type": "Integer",
    "Description": "The number of virtual cores (vcores) used by YARN application master."
  },
  {
    "Key": "yarn.containers.vcores",
    "Default": "-1",
    "Type": "Integer",
    "Description": "The number of virtual cores (vcores) per YARN container. By default, the number of vcores is set to the number of slots per TaskManager, if set, or to 1, otherwise. In order for this parameter to be used your cluster must have CPU scheduling enabled. You can do this by setting the org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler."
  },
  {
    "Key": "yarn.file-replication",
    "Default": "-1",
    "Type": "Integer",
    "Description": "Number of file replication of each local resource file. If it is not configured, Flink will use the default replication value in hadoop configuration."
  },
  {
    "Key": "yarn.flink-dist-jar",
    "Default": "(none)",
    "Type": "String",
    "Description": "The location of the Flink dist jar."
  },
  {
    "Key": "yarn.heartbeat.container-request-interval",
    "Default": "500",
    "Type": "Integer",
    "Description": "Time between heartbeats with the ResourceManager in milliseconds if Flink requests containers: The lower this value is, the faster Flink will get notified about container allocations since requests and allocations are transmitted via heartbeats. The lower this value is, the more excessive containers might get allocated which will eventually be released but put pressure on Yarn. If you observe too many container allocations on the ResourceManager, then it is recommended to increase this value. See this link for more information."
  },
  {
    "Key": "yarn.heartbeat.interval",
    "Default": "5",
    "Type": "Integer",
    "Description": "Time between heartbeats with the ResourceManager in seconds."
  },
  {
    "Key": "yarn.per-job-cluster.include-user-jar",
    "Default": "ORDER",
    "Type": "Enum Possible values: [DISABLED, FIRST, LAST, ORDER]",
    "Description": "Defines whether user-jars are included in the system class path for per-job-clusters as well as their positioning in the path. They can be positioned at the beginning (FIRST), at the end (LAST), or be positioned based on their name (ORDER). DISABLED means the user-jars are excluded from the system class path."
  },
  {
    "Key": "yarn.properties-file.location",
    "Default": "(none)",
    "Type": "String",
    "Description": "When a Flink job is submitted to YARN, the JobManager’s host and the number of available processing slots is written into a properties file, so that the Flink client is able to pick those details up. This configuration parameter allows changing the default location of that file (for example for environments sharing a Flink installation between users)."
  },
  {
    "Key": "yarn.provided.lib.dirs",
    "Default": "(none)",
    "Type": "List\u003cString\u003e",
    "Description": "A semicolon-separated list of provided lib directories. They should be pre-uploaded and world-readable. Flink will use them to exclude the local Flink jars(e.g. flink-dist, lib/, plugins/)uploading to accelerate the job submission process. Also YARN will cache them on the nodes so that they doesn\u0027t need to be downloaded every time for each application. An example could be hdfs://$namenode_address/path/of/flink/lib"
  },
  {
    "Key": "yarn.security.kerberos.additionalFileSystems",
    "Default": "(none)",
    "Type": "List\u003cString\u003e",
    "Description": "A comma-separated list of additional Kerberos-secured Hadoop filesystems Flink is going to access. For example, yarn.security.kerberos.additionalFileSystems\u003dhdfs://namenode2:9002,hdfs://namenode3:9003. The client submitting to YARN needs to have access to these file systems to retrieve the security tokens."
  },
  {
    "Key": "yarn.security.kerberos.localized-keytab-path",
    "Default": "\"krb5.keytab\"",
    "Type": "String",
    "Description": "Local (on NodeManager) path where kerberos keytab file will be localized to. If yarn.security.kerberos.ship-local-keytab set to true, Flink willl ship the keytab file as a YARN local resource. In this case, the path is relative to the local resource directory. If set to false, Flink will try to directly locate the keytab from the path itself."
  },
  {
    "Key": "yarn.security.kerberos.ship-local-keytab",
    "Default": "true",
    "Type": "Boolean",
    "Description": "When this is true Flink will ship the keytab file configured via security.kerberos.login.keytab as a localized YARN resource."
  },
  {
    "Key": "yarn.ship-archives",
    "Default": "(none)",
    "Type": "List\u003cString\u003e",
    "Description": "A semicolon-separated list of archives to be shipped to the YARN cluster. These archives will be un-packed when localizing and they can be any of the following types: \".tar.gz\", \".tar\", \".tgz\", \".dst\", \".jar\", \".zip\"."
  },
  {
    "Key": "yarn.ship-files",
    "Default": "(none)",
    "Type": "List\u003cString\u003e",
    "Description": "A semicolon-separated list of files and/or directories to be shipped to the YARN cluster."
  },
  {
    "Key": "yarn.staging-directory",
    "Default": "(none)",
    "Type": "String",
    "Description": "Staging directory used to store YARN files while submitting applications. Per default, it uses the home directory of the configured file system."
  },
  {
    "Key": "yarn.tags",
    "Default": "(none)",
    "Type": "String",
    "Description": "A comma-separated list of tags to apply to the Flink YARN application."
  },
  {
    "Key": "external-resource.\u003cresource_name\u003e.kubernetes.config-key",
    "Default": "(none)",
    "Type": "String",
    "Description": "If configured, Flink will add \"resources.limits.\u003cconfig-key\u003e\" and \"resources.requests.\u003cconfig-key\u003e\" to the main container of TaskExecutor and set the value to the value of external-resource.\u003cresource_name\u003e.amount."
  },
  {
    "Key": "kubernetes.client.io-pool.size",
    "Default": "4",
    "Type": "Integer",
    "Description": "The size of the IO executor pool used by the Kubernetes client to execute blocking IO operations (e.g. start/stop TaskManager pods, update leader related ConfigMaps, etc.). Increasing the pool size allows to run more IO operations concurrently."
  },
  {
    "Key": "kubernetes.cluster-id",
    "Default": "(none)",
    "Type": "String",
    "Description": "The cluster-id, which should be no more than 45 characters, is used for identifying a unique Flink cluster. The id must only contain lowercase alphanumeric characters and \"-\". The required format is [a-z]([-a-z0-9]*[a-z0-9]). If not set, the client will automatically generate it with a random ID."
  },
  {
    "Key": "kubernetes.config.file",
    "Default": "(none)",
    "Type": "String",
    "Description": "The kubernetes config file will be used to create the client. The default is located at ~/.kube/config"
  },
  {
    "Key": "kubernetes.container.image",
    "Default": "The default value depends on the actually running version. In general it looks like \"flink:\u003cFLINK_VERSION\u003e-scala_\u003cSCALA_VERSION\u003e\"",
    "Type": "String",
    "Description": "Image to use for Flink containers. The specified image must be based upon the same Apache Flink and Scala versions as used by the application. Visit here for the official docker images provided by the Flink project. The Flink project also publishes docker images to apache/flink DockerHub repository."
  },
  {
    "Key": "kubernetes.container.image.pull-policy",
    "Default": "IfNotPresent",
    "Type": "Enum Possible values: [IfNotPresent, Always, Never]",
    "Description": "The Kubernetes container image pull policy (IfNotPresent or Always or Never). The default policy is IfNotPresent to avoid putting pressure to image repository."
  },
  {
    "Key": "kubernetes.container.image.pull-secrets",
    "Default": "(none)",
    "Type": "List\u003cString\u003e",
    "Description": "A semicolon-separated list of the Kubernetes secrets used to access private image registries."
  },
  {
    "Key": "kubernetes.context",
    "Default": "(none)",
    "Type": "String",
    "Description": "The desired context from your Kubernetes config file used to configure the Kubernetes client for interacting with the cluster. This could be helpful if one has multiple contexts configured and wants to administrate different Flink clusters on different Kubernetes clusters/contexts."
  },
  {
    "Key": "kubernetes.entry.path",
    "Default": "\"/docker-entrypoint.sh\"",
    "Type": "String",
    "Description": "The entrypoint script of kubernetes in the image. It will be used as command for jobmanager and taskmanager container."
  },
  {
    "Key": "kubernetes.env.secretKeyRef",
    "Default": "(none)",
    "Type": "List\u003cMap\u003e",
    "Description": "The user-specified secrets to set env variables in Flink container. The value should be in the form of env:FOO_ENV,secret:foo_secret,key:foo_key;env:BAR_ENV,secret:bar_secret,key:bar_key."
  },
  {
    "Key": "kubernetes.flink.conf.dir",
    "Default": "\"/opt/flink/conf\"",
    "Type": "String",
    "Description": "The flink conf directory that will be mounted in pod. The flink-conf.yaml, log4j.properties, logback.xml in this path will be overwritten from config map."
  },
  {
    "Key": "kubernetes.flink.log.dir",
    "Default": "(none)",
    "Type": "String",
    "Description": "The directory that logs of jobmanager and taskmanager be saved in the pod. The default value is $FLINK_HOME/log."
  },
  {
    "Key": "kubernetes.hadoop.conf.config-map.name",
    "Default": "(none)",
    "Type": "String",
    "Description": "Specify the name of an existing ConfigMap that contains custom Hadoop configuration to be mounted on the JobManager(s) and TaskManagers."
  },
  {
    "Key": "kubernetes.jobmanager.annotations",
    "Default": "(none)",
    "Type": "Map",
    "Description": "The user-specified annotations that are set to the JobManager pod. The value could be in the form of a1:v1,a2:v2"
  },
  {
    "Key": "kubernetes.jobmanager.cpu",
    "Default": "1.0",
    "Type": "Double",
    "Description": "The number of cpu used by job manager"
  },
  {
    "Key": "kubernetes.jobmanager.labels",
    "Default": "(none)",
    "Type": "Map",
    "Description": "The labels to be set for JobManager pod. Specified as key:value pairs separated by commas. For example, version:alphav1,deploy:test."
  },
  {
    "Key": "kubernetes.jobmanager.node-selector",
    "Default": "(none)",
    "Type": "Map",
    "Description": "The node selector to be set for JobManager pod. Specified as key:value pairs separated by commas. For example, environment:production,disk:ssd."
  },
  {
    "Key": "kubernetes.jobmanager.owner.reference",
    "Default": "(none)",
    "Type": "List\u003cMap\u003e",
    "Description": "The user-specified Owner References to be set to the JobManager Deployment. When all the owner resources are deleted, the JobManager Deployment will be deleted automatically, which also deletes all the resources created by this Flink cluster. The value should be formatted as a semicolon-separated list of owner references, where each owner reference is a comma-separated list of `key:value` pairs. E.g., apiVersion:v1,blockOwnerDeletion:true,controller:true,kind:FlinkApplication,name:flink-app-name,uid:flink-app-uid;apiVersion:v1,kind:Deployment,name:deploy-name,uid:deploy-uid"
  },
  {
    "Key": "kubernetes.jobmanager.service-account",
    "Default": "\"default\"",
    "Type": "String",
    "Description": "Service account that is used by jobmanager within kubernetes cluster. The job manager uses this service account when requesting taskmanager pods from the API server. If not explicitly configured, config option \u0027kubernetes.service-account\u0027 will be used."
  },
  {
    "Key": "kubernetes.jobmanager.tolerations",
    "Default": "(none)",
    "Type": "List\u003cMap\u003e",
    "Description": "The user-specified tolerations to be set to the JobManager pod. The value should be in the form of key:key1,operator:Equal,value:value1,effect:NoSchedule;key:key2,operator:Exists,effect:NoExecute,tolerationSeconds:6000"
  },
  {
    "Key": "kubernetes.namespace",
    "Default": "\"default\"",
    "Type": "String",
    "Description": "The namespace that will be used for running the jobmanager and taskmanager pods."
  },
  {
    "Key": "kubernetes.pod-template-file",
    "Default": "(none)",
    "Type": "String",
    "Description": "Specify a local file that contains the pod template definition. It will be used to initialize the jobmanager and taskmanager pod. The main container should be defined with name \u0027flink-main-container\u0027. Notice that this can be overwritten by config options \u0027kubernetes.pod-template-file.jobmanager\u0027 and \u0027kubernetes.pod-template-file.taskmanager\u0027 for jobmanager and taskmanager respectively."
  },
  {
    "Key": "kubernetes.pod-template-file.jobmanager",
    "Default": "(none)",
    "Type": "String",
    "Description": "Specify a local file that contains the jobmanager pod template definition. It will be used to initialize the jobmanager pod. The main container should be defined with name \u0027flink-main-container\u0027. If not explicitly configured, config option \u0027kubernetes.pod-template-file\u0027 will be used."
  },
  {
    "Key": "kubernetes.pod-template-file.taskmanager",
    "Default": "(none)",
    "Type": "String",
    "Description": "Specify a local file that contains the taskmanager pod template definition. It will be used to initialize the taskmanager pod. The main container should be defined with name \u0027flink-main-container\u0027. If not explicitly configured, config option \u0027kubernetes.pod-template-file\u0027 will be used."
  },
  {
    "Key": "kubernetes.rest-service.annotations",
    "Default": "(none)",
    "Type": "Map",
    "Description": "The user-specified annotations that are set to the rest Service. The value should be in the form of a1:v1,a2:v2"
  },
  {
    "Key": "kubernetes.rest-service.exposed.type",
    "Default": "LoadBalancer",
    "Type": "Enum Possible values: [ClusterIP, NodePort, LoadBalancer]",
    "Description": "The exposed type of the rest service (ClusterIP or NodePort or LoadBalancer). The exposed rest service could be used to access the Flink’s Web UI and REST endpoint."
  },
  {
    "Key": "kubernetes.secrets",
    "Default": "(none)",
    "Type": "Map",
    "Description": "The user-specified secrets that will be mounted into Flink container. The value should be in the form of foo:/opt/secrets-foo,bar:/opt/secrets-bar."
  },
  {
    "Key": "kubernetes.service-account",
    "Default": "\"default\"",
    "Type": "String",
    "Description": "Service account that is used by jobmanager and taskmanager within kubernetes cluster. Notice that this can be overwritten by config options \u0027kubernetes.jobmanager.service-account\u0027 and \u0027kubernetes.taskmanager.service-account\u0027 for jobmanager and taskmanager respectively."
  },
  {
    "Key": "kubernetes.taskmanager.annotations",
    "Default": "(none)",
    "Type": "Map",
    "Description": "The user-specified annotations that are set to the TaskManager pod. The value could be in the form of a1:v1,a2:v2"
  },
  {
    "Key": "kubernetes.taskmanager.cpu",
    "Default": "-1.0",
    "Type": "Double",
    "Description": "The number of cpu used by task manager. By default, the cpu is set to the number of slots per TaskManager"
  },
  {
    "Key": "kubernetes.taskmanager.labels",
    "Default": "(none)",
    "Type": "Map",
    "Description": "The labels to be set for TaskManager pods. Specified as key:value pairs separated by commas. For example, version:alphav1,deploy:test."
  },
  {
    "Key": "kubernetes.taskmanager.node-selector",
    "Default": "(none)",
    "Type": "Map",
    "Description": "The node selector to be set for TaskManager pods. Specified as key:value pairs separated by commas. For example, environment:production,disk:ssd."
  },
  {
    "Key": "kubernetes.taskmanager.service-account",
    "Default": "\"default\"",
    "Type": "String",
    "Description": "Service account that is used by taskmanager within kubernetes cluster. The task manager uses this service account when watching config maps on the API server to retrieve leader address of jobmanager and resourcemanager. If not explicitly configured, config option \u0027kubernetes.service-account\u0027 will be used."
  },
  {
    "Key": "kubernetes.taskmanager.tolerations",
    "Default": "(none)",
    "Type": "List\u003cMap\u003e",
    "Description": "The user-specified tolerations to be set to the TaskManager pod. The value should be in the form of key:key1,operator:Equal,value:value1,effect:NoSchedule;key:key2,operator:Exists,effect:NoExecute,tolerationSeconds:6000"
  },
  {
    "Key": "kubernetes.transactional-operation.max-retries",
    "Default": "5",
    "Type": "Integer",
    "Description": "Defines the number of Kubernetes transactional operation retries before the client gives up. For example, FlinkKubeClient#checkAndUpdateConfigMap."
  },
  {
    "Key": "mesos.failover-timeout",
    "Default": "604800",
    "Type": "Integer",
    "Description": "The failover timeout in seconds for the Mesos scheduler, after which running tasks are automatically shut down."
  },
  {
    "Key": "mesos.master",
    "Default": "(none)",
    "Type": "String",
    "Description": "The Mesos master URL. The value should be in one of the following forms: host:port zk://host1:port1,host2:port2,.../path zk://username:password@host1:port1,host2:port2,.../path file:///path/to/file"
  },
  {
    "Key": "mesos.resourcemanager.artifactserver.port",
    "Default": "0",
    "Type": "Integer",
    "Description": "The config parameter defining the Mesos artifact server port to use. Setting the port to 0 will let the OS choose an available port."
  },
  {
    "Key": "mesos.resourcemanager.artifactserver.ssl.enabled",
    "Default": "true",
    "Type": "Boolean",
    "Description": "Enables SSL for the Flink artifact server. Note that security.ssl.enabled also needs to be set to true encryption to enable encryption."
  },
  {
    "Key": "mesos.resourcemanager.declined-offer-refuse-duration",
    "Default": "5000",
    "Type": "Long",
    "Description": "Amount of time to ask the Mesos master to not resend a declined resource offer again. This ensures a declined resource offer isn\u0027t resent immediately after being declined"
  },
  {
    "Key": "mesos.resourcemanager.framework.name",
    "Default": "\"Flink\"",
    "Type": "String",
    "Description": "Mesos framework name"
  },
  {
    "Key": "mesos.resourcemanager.framework.principal",
    "Default": "(none)",
    "Type": "String",
    "Description": "Mesos framework principal"
  },
  {
    "Key": "mesos.resourcemanager.framework.role",
    "Default": "\"*\"",
    "Type": "String",
    "Description": "Mesos framework role definition"
  },
  {
    "Key": "mesos.resourcemanager.framework.secret",
    "Default": "(none)",
    "Type": "String",
    "Description": "Mesos framework secret"
  },
  {
    "Key": "mesos.resourcemanager.framework.user",
    "Default": "(none)",
    "Type": "String",
    "Description": "Mesos framework user"
  },
  {
    "Key": "mesos.resourcemanager.tasks.port-assignments",
    "Default": "(none)",
    "Type": "String",
    "Description": "Comma-separated list of configuration keys which represent a configurable port. All port keys will dynamically get a port assigned through Mesos."
  },
  {
    "Key": "mesos.resourcemanager.unused-offer-expiration",
    "Default": "120000",
    "Type": "Long",
    "Description": "Amount of time to wait for unused expired offers before declining them. This ensures your scheduler will not hoard unuseful offers."
  },
  {
    "Key": "mesos.constraints.hard.hostattribute",
    "Default": "(none)",
    "Type": "String",
    "Description": "Constraints for task placement on Mesos based on agent attributes. Takes a comma-separated list of key:value pairs corresponding to the attributes exposed by the target mesos agents. Example: az:eu-west-1a,series:t2"
  },
  {
    "Key": "mesos.resourcemanager.network.resource.name",
    "Default": "\"network\"",
    "Type": "String",
    "Description": "Network resource name on Mesos cluster."
  },
  {
    "Key": "mesos.resourcemanager.tasks.bootstrap-cmd",
    "Default": "(none)",
    "Type": "String",
    "Description": "A command which is executed before the TaskManager is started."
  },
  {
    "Key": "mesos.resourcemanager.tasks.container.docker.force-pull-image",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Instruct the docker containerizer to forcefully pull the image rather than reuse a cached version."
  },
  {
    "Key": "mesos.resourcemanager.tasks.container.docker.parameters",
    "Default": "(none)",
    "Type": "String",
    "Description": "Custom parameters to be passed into docker run command when using the docker containerizer. Comma separated list of \"key\u003dvalue\" pairs. The \"value\" may contain \u0027\u003d\u0027."
  },
  {
    "Key": "mesos.resourcemanager.tasks.container.image.name",
    "Default": "(none)",
    "Type": "String",
    "Description": "Image name to use for the container."
  },
  {
    "Key": "mesos.resourcemanager.tasks.container.type",
    "Default": "\"mesos\"",
    "Type": "String",
    "Description": "Type of the containerization used: “mesos” or “docker”."
  },
  {
    "Key": "mesos.resourcemanager.tasks.container.volumes",
    "Default": "(none)",
    "Type": "String",
    "Description": "A comma separated list of [host_path:]container_path[:RO|RW]. This allows for mounting additional volumes into your container."
  },
  {
    "Key": "mesos.resourcemanager.tasks.cpus",
    "Default": "0.0",
    "Type": "Double",
    "Description": "CPUs to assign to the Mesos workers."
  },
  {
    "Key": "mesos.resourcemanager.tasks.disk",
    "Default": "0",
    "Type": "Integer",
    "Description": "Disk space to assign to the Mesos workers in MB."
  },
  {
    "Key": "mesos.resourcemanager.tasks.gpus",
    "Default": "0",
    "Type": "Integer",
    "Description": "GPUs to assign to the Mesos workers."
  },
  {
    "Key": "mesos.resourcemanager.tasks.hostname",
    "Default": "(none)",
    "Type": "String",
    "Description": "Optional value to define the TaskManager’s hostname. The pattern _TASK_ is replaced by the actual id of the Mesos task. This can be used to configure the TaskManager to use Mesos DNS (e.g. _TASK_.flink-service.mesos) for name lookups."
  },
  {
    "Key": "mesos.resourcemanager.tasks.labels",
    "Default": "(none)",
    "Type": "Map",
    "Description": "Labels to set on mesos tasks. It is a comma separated list of key value pairs, with each key value pair joined by colon. e.g. key1:value1,key2:value2"
  },
  {
    "Key": "mesos.resourcemanager.tasks.network.bandwidth",
    "Default": "0",
    "Type": "Integer",
    "Description": "Network bandwidth to assign to the Mesos workers in MB per sec."
  },
  {
    "Key": "mesos.resourcemanager.tasks.taskmanager-cmd",
    "Default": "\"$FLINK_HOME/bin/mesos-taskmanager.sh\"",
    "Type": "String",
    "Description": ""
  },
  {
    "Key": "mesos.resourcemanager.tasks.uris",
    "Default": "(none)",
    "Type": "String",
    "Description": "A comma separated list of URIs of custom artifacts to be downloaded into the sandbox of Mesos workers."
  },
  {
    "Key": "mesos.resourcemanager.tasks.user",
    "Default": "(none)",
    "Type": "String",
    "Description": "Unix user which mesos tasks should run as."
  },
  {
    "Key": "state.backend.rocksdb.memory.fixed-per-slot",
    "Default": "(none)",
    "Type": "MemorySize",
    "Description": "The fixed total amount of memory, shared among all RocksDB instances per slot. This option overrides the \u0027state.backend.rocksdb.memory.managed\u0027 option when configured. If neither this option, nor the \u0027state.backend.rocksdb.memory.managed\u0027 optionare set, then each RocksDB column family state has its own memory caches (as controlled by the column family options)."
  },
  {
    "Key": "state.backend.rocksdb.memory.high-prio-pool-ratio",
    "Default": "0.1",
    "Type": "Double",
    "Description": "The fraction of cache memory that is reserved for high-priority data like index, filter, and compression dictionary blocks. This option only has an effect when \u0027state.backend.rocksdb.memory.managed\u0027 or \u0027state.backend.rocksdb.memory.fixed-per-slot\u0027 are configured."
  },
  {
    "Key": "state.backend.rocksdb.memory.managed",
    "Default": "true",
    "Type": "Boolean",
    "Description": "If set, the RocksDB state backend will automatically configure itself to use the managed memory budget of the task slot, and divide the memory over write buffers, indexes, block caches, etc. That way, the three major uses of memory of RocksDB will be capped."
  },
  {
    "Key": "state.backend.rocksdb.memory.partitioned-index-filters",
    "Default": "false",
    "Type": "Boolean",
    "Description": "With partitioning, the index/filter block of an SST file is partitioned into smaller blocks with an additional top-level index on them. When reading an index/filter, only top-level index is loaded into memory. The partitioned index/filter then uses the top-level index to load on demand into the block cache the partitions that are required to perform the index/filter query. This option only has an effect when \u0027state.backend.rocksdb.memory.managed\u0027 or \u0027state.backend.rocksdb.memory.fixed-per-slot\u0027 are configured."
  },
  {
    "Key": "state.backend.rocksdb.memory.write-buffer-ratio",
    "Default": "0.5",
    "Type": "Double",
    "Description": "The maximum amount of memory that write buffers may take, as a fraction of the total shared memory. This option only has an effect when \u0027state.backend.rocksdb.memory.managed\u0027 or \u0027state.backend.rocksdb.memory.fixed-per-slot\u0027 are configured."
  },
  {
    "Key": "state.backend.rocksdb.timer-service.factory",
    "Default": "ROCKSDB",
    "Type": "Enum Possible values: [HEAP, ROCKSDB]",
    "Description": "This determines the factory for timer service state implementation. Options are either HEAP (heap-based) or ROCKSDB for an implementation based on RocksDB."
  },
  {
    "Key": "metrics.fetcher.update-interval",
    "Default": "10000",
    "Type": "Long",
    "Description": "Update interval for the metric fetcher used by the web UI in milliseconds. Decrease this value for faster updating metrics. Increase this value if the metric fetcher causes too much load. Setting this value to 0 disables the metric fetching completely."
  },
  {
    "Key": "metrics.internal.query-service.port",
    "Default": "\"0\"",
    "Type": "String",
    "Description": "The port range used for Flink\u0027s internal metric query service. Accepts a list of ports (“50100,50101”), ranges(“50100-50200”) or a combination of both. It is recommended to set a range of ports to avoid collisions when multiple Flink components are running on the same machine. Per default Flink will pick a random port."
  },
  {
    "Key": "metrics.internal.query-service.thread-priority",
    "Default": "1",
    "Type": "Integer",
    "Description": "The thread priority used for Flink\u0027s internal metric query service. The thread is created by Akka\u0027s thread pool executor. The range of the priority is from 1 (MIN_PRIORITY) to 10 (MAX_PRIORITY). Warning, increasing this value may bring the main Flink components down."
  },
  {
    "Key": "metrics.latency.granularity",
    "Default": "\"operator\"",
    "Type": "String",
    "Description": "Defines the granularity of latency metrics. Accepted values are: single - Track latency without differentiating between sources and subtasks. operator - Track latency while differentiating between sources, but not subtasks. subtask - Track latency while differentiating between sources and subtasks."
  },
  {
    "Key": "metrics.latency.history-size",
    "Default": "128",
    "Type": "Integer",
    "Description": "Defines the number of measured latencies to maintain at each operator."
  },
  {
    "Key": "metrics.latency.interval",
    "Default": "0",
    "Type": "Long",
    "Description": "Defines the interval at which latency tracking marks are emitted from the sources. Disables latency tracking if set to 0 or a negative value. Enabling this feature can significantly impact the performance of the cluster."
  },
  {
    "Key": "metrics.reporter.\u003cname\u003e.\u003cparameter\u003e",
    "Default": "(none)",
    "Type": "String",
    "Description": "Configures the parameter \u003cparameter\u003e for the reporter named \u003cname\u003e."
  },
  {
    "Key": "metrics.reporter.\u003cname\u003e.class",
    "Default": "(none)",
    "Type": "String",
    "Description": "The reporter class to use for the reporter named \u003cname\u003e."
  },
  {
    "Key": "metrics.reporter.\u003cname\u003e.interval",
    "Default": "10 s",
    "Type": "Duration",
    "Description": "The reporter interval to use for the reporter named \u003cname\u003e."
  },
  {
    "Key": "metrics.reporters",
    "Default": "(none)",
    "Type": "String",
    "Description": "An optional list of reporter names. If configured, only reporters whose name matches any of the names in the list will be started. Otherwise, all reporters that could be found in the configuration will be started."
  },
  {
    "Key": "metrics.scope.delimiter",
    "Default": "\".\"",
    "Type": "String",
    "Description": "Delimiter used to assemble the metric identifier."
  },
  {
    "Key": "metrics.scope.jm",
    "Default": "\"\u003chost\u003e.jobmanager\"",
    "Type": "String",
    "Description": "Defines the scope format string that is applied to all metrics scoped to a JobManager."
  },
  {
    "Key": "metrics.scope.jm.job",
    "Default": "\"\u003chost\u003e.jobmanager.\u003cjob_name\u003e\"",
    "Type": "String",
    "Description": "Defines the scope format string that is applied to all metrics scoped to a job on a JobManager."
  },
  {
    "Key": "metrics.scope.operator",
    "Default": "\"\u003chost\u003e.taskmanager.\u003ctm_id\u003e.\u003cjob_name\u003e.\u003coperator_name\u003e.\u003csubtask_index\u003e\"",
    "Type": "String",
    "Description": "Defines the scope format string that is applied to all metrics scoped to an operator."
  },
  {
    "Key": "metrics.scope.task",
    "Default": "\"\u003chost\u003e.taskmanager.\u003ctm_id\u003e.\u003cjob_name\u003e.\u003ctask_name\u003e.\u003csubtask_index\u003e\"",
    "Type": "String",
    "Description": "Defines the scope format string that is applied to all metrics scoped to a task."
  },
  {
    "Key": "metrics.scope.tm",
    "Default": "\"\u003chost\u003e.taskmanager.\u003ctm_id\u003e\"",
    "Type": "String",
    "Description": "Defines the scope format string that is applied to all metrics scoped to a TaskManager."
  },
  {
    "Key": "metrics.scope.tm.job",
    "Default": "\"\u003chost\u003e.taskmanager.\u003ctm_id\u003e.\u003cjob_name\u003e\"",
    "Type": "String",
    "Description": "Defines the scope format string that is applied to all metrics scoped to a job on a TaskManager."
  },
  {
    "Key": "metrics.system-resource",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Flag indicating whether Flink should report system resource metrics such as machine\u0027s CPU, memory or network usage."
  },
  {
    "Key": "metrics.system-resource-probing-interval",
    "Default": "5000",
    "Type": "Long",
    "Description": "Interval between probing of system resource metrics specified in milliseconds. Has an effect only when \u0027metrics.system-resource\u0027 is enabled."
  },
  {
    "Key": "state.backend.rocksdb.metrics.actual-delayed-write-rate",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Monitor the current actual delayed write rate. 0 means no delay."
  },
  {
    "Key": "state.backend.rocksdb.metrics.background-errors",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Monitor the number of background errors in RocksDB."
  },
  {
    "Key": "state.backend.rocksdb.metrics.block-cache-capacity",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Monitor block cache capacity."
  },
  {
    "Key": "state.backend.rocksdb.metrics.block-cache-pinned-usage",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Monitor the memory size for the entries being pinned in block cache."
  },
  {
    "Key": "state.backend.rocksdb.metrics.block-cache-usage",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Monitor the memory size for the entries residing in block cache."
  },
  {
    "Key": "state.backend.rocksdb.metrics.column-family-as-variable",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Whether to expose the column family as a variable."
  },
  {
    "Key": "state.backend.rocksdb.metrics.compaction-pending",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Track pending compactions in RocksDB. Returns 1 if a compaction is pending, 0 otherwise."
  },
  {
    "Key": "state.backend.rocksdb.metrics.cur-size-active-mem-table",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Monitor the approximate size of the active memtable in bytes."
  },
  {
    "Key": "state.backend.rocksdb.metrics.cur-size-all-mem-tables",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Monitor the approximate size of the active and unflushed immutable memtables in bytes."
  },
  {
    "Key": "state.backend.rocksdb.metrics.estimate-live-data-size",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Estimate of the amount of live data in bytes."
  },
  {
    "Key": "state.backend.rocksdb.metrics.estimate-num-keys",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Estimate the number of keys in RocksDB."
  },
  {
    "Key": "state.backend.rocksdb.metrics.estimate-pending-compaction-bytes",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Estimated total number of bytes compaction needs to rewrite to get all levels down to under target size. Not valid for other compactions than level-based."
  },
  {
    "Key": "state.backend.rocksdb.metrics.estimate-table-readers-mem",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Estimate the memory used for reading SST tables, excluding memory used in block cache (e.g.,filter and index blocks) in bytes."
  },
  {
    "Key": "state.backend.rocksdb.metrics.is-write-stopped",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Track whether write has been stopped in RocksDB. Returns 1 if write has been stopped, 0 otherwise."
  },
  {
    "Key": "state.backend.rocksdb.metrics.mem-table-flush-pending",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Monitor the number of pending memtable flushes in RocksDB."
  },
  {
    "Key": "state.backend.rocksdb.metrics.num-deletes-active-mem-table",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Monitor the total number of delete entries in the active memtable."
  },
  {
    "Key": "state.backend.rocksdb.metrics.num-deletes-imm-mem-tables",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Monitor the total number of delete entries in the unflushed immutable memtables."
  },
  {
    "Key": "state.backend.rocksdb.metrics.num-entries-active-mem-table",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Monitor the total number of entries in the active memtable."
  },
  {
    "Key": "state.backend.rocksdb.metrics.num-entries-imm-mem-tables",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Monitor the total number of entries in the unflushed immutable memtables."
  },
  {
    "Key": "state.backend.rocksdb.metrics.num-immutable-mem-table",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Monitor the number of immutable memtables in RocksDB."
  },
  {
    "Key": "state.backend.rocksdb.metrics.num-live-versions",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Monitor number of live versions. Version is an internal data structure. See RocksDB file version_set.h for details. More live versions often mean more SST files are held from being deleted, by iterators or unfinished compactions."
  },
  {
    "Key": "state.backend.rocksdb.metrics.num-running-compactions",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Monitor the number of currently running compactions."
  },
  {
    "Key": "state.backend.rocksdb.metrics.num-running-flushes",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Monitor the number of currently running flushes."
  },
  {
    "Key": "state.backend.rocksdb.metrics.num-snapshots",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Monitor the number of unreleased snapshots of the database."
  },
  {
    "Key": "state.backend.rocksdb.metrics.size-all-mem-tables",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Monitor the approximate size of the active, unflushed immutable, and pinned immutable memtables in bytes."
  },
  {
    "Key": "state.backend.rocksdb.metrics.total-sst-files-size",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Monitor the total size (bytes) of all SST files.WARNING: may slow down online queries if there are too many files."
  },
  {
    "Key": "historyserver.archive.clean-expired-jobs",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Whether HistoryServer should cleanup jobs that are no longer present `historyserver.archive.fs.dir`."
  },
  {
    "Key": "historyserver.archive.fs.dir",
    "Default": "(none)",
    "Type": "String",
    "Description": "Comma separated list of directories to fetch archived jobs from. The history server will monitor these directories for archived jobs. You can configure the JobManager to archive jobs to a directory via `jobmanager.archive.fs.dir`."
  },
  {
    "Key": "historyserver.archive.fs.refresh-interval",
    "Default": "10000",
    "Type": "Long",
    "Description": "Interval in milliseconds for refreshing the archived job directories."
  },
  {
    "Key": "historyserver.archive.retained-jobs",
    "Default": "-1",
    "Type": "Integer",
    "Description": "The maximum number of jobs to retain in each archive directory defined by `historyserver.archive.fs.dir`. If set to `-1`(default), there is no limit to the number of archives. If set to `0` or less than `-1` HistoryServer will throw an IllegalConfigurationException."
  },
  {
    "Key": "historyserver.web.address",
    "Default": "(none)",
    "Type": "String",
    "Description": "Address of the HistoryServer\u0027s web interface."
  },
  {
    "Key": "historyserver.web.port",
    "Default": "8082",
    "Type": "Integer",
    "Description": "Port of the HistoryServers\u0027s web interface."
  },
  {
    "Key": "historyserver.web.refresh-interval",
    "Default": "10000",
    "Type": "Long",
    "Description": "The refresh interval for the HistoryServer web-frontend in milliseconds."
  },
  {
    "Key": "historyserver.web.ssl.enabled",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Enable HTTPs access to the HistoryServer web frontend. This is applicable only when the global SSL flag security.ssl.enabled is set to true."
  },
  {
    "Key": "historyserver.web.tmpdir",
    "Default": "(none)",
    "Type": "String",
    "Description": "This configuration parameter allows defining the Flink web directory to be used by the history server web interface. The web interface will copy its static files into the directory."
  },
  {
    "Key": "queryable-state.client.network-threads",
    "Default": "0",
    "Type": "Integer",
    "Description": "Number of network (Netty\u0027s event loop) Threads for queryable state client."
  },
  {
    "Key": "queryable-state.enable",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Option whether the queryable state proxy and server should be enabled where possible and configurable."
  },
  {
    "Key": "queryable-state.proxy.network-threads",
    "Default": "0",
    "Type": "Integer",
    "Description": "Number of network (Netty\u0027s event loop) Threads for queryable state proxy."
  },
  {
    "Key": "queryable-state.proxy.ports",
    "Default": "\"9069\"",
    "Type": "String",
    "Description": "The port range of the queryable state proxy. The specified range can be a single port: \"9123\", a range of ports: \"50100-50200\", or a list of ranges and ports: \"50100-50200,50300-50400,51234\"."
  },
  {
    "Key": "queryable-state.proxy.query-threads",
    "Default": "0",
    "Type": "Integer",
    "Description": "Number of query Threads for queryable state proxy. Uses the number of slots if set to 0."
  },
  {
    "Key": "queryable-state.server.network-threads",
    "Default": "0",
    "Type": "Integer",
    "Description": "Number of network (Netty\u0027s event loop) Threads for queryable state server."
  },
  {
    "Key": "queryable-state.server.ports",
    "Default": "\"9067\"",
    "Type": "String",
    "Description": "The port range of the queryable state server. The specified range can be a single port: \"9123\", a range of ports: \"50100-50200\", or a list of ranges and ports: \"50100-50200,50300-50400,51234\"."
  },
  {
    "Key": "queryable-state.server.query-threads",
    "Default": "0",
    "Type": "Integer",
    "Description": "Number of query Threads for queryable state server. Uses the number of slots if set to 0."
  },
  {
    "Key": "client.retry-period",
    "Default": "2 s",
    "Type": "Duration",
    "Description": "The interval (in ms) between consecutive retries of failed attempts to execute commands through the CLI or Flink\u0027s clients, wherever retry is supported (default 2sec)."
  },
  {
    "Key": "client.timeout",
    "Default": "1 min",
    "Type": "Duration",
    "Description": "Timeout on the client side."
  },
  {
    "Key": "execution.attached",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Specifies if the pipeline is submitted in attached or detached mode."
  },
  {
    "Key": "execution.job-listeners",
    "Default": "(none)",
    "Type": "List\u003cString\u003e",
    "Description": "Custom JobListeners to be registered with the execution environment. The registered listeners cannot have constructors with arguments."
  },
  {
    "Key": "execution.shutdown-on-attached-exit",
    "Default": "false",
    "Type": "Boolean",
    "Description": "If the job is submitted in attached mode, perform a best-effort cluster shutdown when the CLI is terminated abruptly, e.g., in response to a user interrupt, such as typing Ctrl + C."
  },
  {
    "Key": "execution.target",
    "Default": "(none)",
    "Type": "String",
    "Description": "The deployment target for the execution. This can take one of the following values when calling bin/flink run: remote local yarn-per-job yarn-session kubernetes-session And one of the following values when calling bin/flink run-application: yarn-application kubernetes-application"
  },
  {
    "Key": "execution.savepoint.ignore-unclaimed-state",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Allow to skip savepoint state that cannot be restored. Allow this if you removed an operator from your pipeline after the savepoint was triggered."
  },
  {
    "Key": "execution.savepoint.path",
    "Default": "(none)",
    "Type": "String",
    "Description": "Path to a savepoint to restore the job from (for example hdfs:///flink/savepoint-1537)."
  },
  {
    "Key": "execution.buffer-timeout",
    "Default": "100 ms",
    "Type": "Duration",
    "Description": "The maximum time frequency (milliseconds) for the flushing of the output buffers. By default the output buffers flush frequently to provide low latency and to aid smooth developer experience. Setting the parameter can result in three logical modes: A positive value triggers flushing periodically by that interval 0 triggers flushing after every record thus minimizing latency -1 ms triggers flushing only when the output buffer is full thus maximizing throughput"
  },
  {
    "Key": "execution.checkpointing.snapshot-compression",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Tells if we should use compression for the state snapshot data or not"
  },
  {
    "Key": "execution.runtime-mode",
    "Default": "STREAMING",
    "Type": "Enum Possible values: [STREAMING, BATCH, AUTOMATIC]",
    "Description": "Runtime execution mode of DataStream programs. Among other things, this controls task scheduling, network shuffle behavior, and time semantics."
  },
  {
    "Key": "pipeline.auto-generate-uids",
    "Default": "true",
    "Type": "Boolean",
    "Description": "When auto-generated UIDs are disabled, users are forced to manually specify UIDs on DataStream applications. It is highly recommended that users specify UIDs before deploying to production since they are used to match state in savepoints to operators in a job. Because auto-generated ID\u0027s are likely to change when modifying a job, specifying custom IDs allow an application to evolve over time without discarding state."
  },
  {
    "Key": "pipeline.auto-type-registration",
    "Default": "true",
    "Type": "Boolean",
    "Description": "Controls whether Flink is automatically registering all types in the user programs with Kryo."
  },
  {
    "Key": "pipeline.auto-watermark-interval",
    "Default": "0 ms",
    "Type": "Duration",
    "Description": "The interval of the automatic watermark emission. Watermarks are used throughout the streaming system to keep track of the progress of time. They are used, for example, for time based windowing."
  },
  {
    "Key": "pipeline.cached-files",
    "Default": "(none)",
    "Type": "List\u003cString\u003e",
    "Description": "Files to be registered at the distributed cache under the given name. The files will be accessible from any user-defined function in the (distributed) runtime under a local path. Files may be local files (which will be distributed via BlobServer), or files in a distributed file system. The runtime will copy the files temporarily to a local cache, if needed. Example: name:file1,path:`file:///tmp/file1`;name:file2,path:`hdfs:///tmp/file2`"
  },
  {
    "Key": "pipeline.classpaths",
    "Default": "(none)",
    "Type": "List\u003cString\u003e",
    "Description": "A semicolon-separated list of the classpaths to package with the job jars to be sent to the cluster. These have to be valid URLs."
  },
  {
    "Key": "pipeline.closure-cleaner-level",
    "Default": "RECURSIVE",
    "Type": "Enum Possible values: [NONE, TOP_LEVEL, RECURSIVE]",
    "Description": "Configures the mode in which the closure cleaner works NONE - disables the closure cleaner completely TOP_LEVEL - cleans only the top-level class without recursing into fields RECURSIVE - cleans all the fields recursively"
  },
  {
    "Key": "pipeline.default-kryo-serializers",
    "Default": "(none)",
    "Type": "List\u003cString\u003e",
    "Description": "Semicolon separated list of pairs of class names and Kryo serializers class names to be used as Kryo default serializers Example: class:org.example.ExampleClass,serializer:org.example.ExampleSerializer1; class:org.example.ExampleClass2,serializer:org.example.ExampleSerializer2"
  },
  {
    "Key": "pipeline.force-avro",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Forces Flink to use the Apache Avro serializer for POJOs. Important: Make sure to include the flink-avro module."
  },
  {
    "Key": "pipeline.force-kryo",
    "Default": "false",
    "Type": "Boolean",
    "Description": "If enabled, forces TypeExtractor to use Kryo serializer for POJOS even though we could analyze as POJO. In some cases this might be preferable. For example, when using interfaces with subclasses that cannot be analyzed as POJO."
  },
  {
    "Key": "pipeline.generic-types",
    "Default": "true",
    "Type": "Boolean",
    "Description": "If the use of generic types is disabled, Flink will throw an UnsupportedOperationException whenever it encounters a data type that would go through Kryo for serialization. Disabling generic types can be helpful to eagerly find and eliminate the use of types that would go through Kryo serialization during runtime. Rather than checking types individually, using this option will throw exceptions eagerly in the places where generic types are used. We recommend to use this option only during development and pre-production phases, not during actual production use. The application program and/or the input data may be such that new, previously unseen, types occur at some point. In that case, setting this option would cause the program to fail."
  },
  {
    "Key": "pipeline.global-job-parameters",
    "Default": "(none)",
    "Type": "Map",
    "Description": "Register a custom, serializable user configuration object. The configuration can be accessed in operators"
  },
  {
    "Key": "pipeline.jars",
    "Default": "(none)",
    "Type": "List\u003cString\u003e",
    "Description": "A semicolon-separated list of the jars to package with the job jars to be sent to the cluster. These have to be valid paths."
  },
  {
    "Key": "pipeline.max-parallelism",
    "Default": "-1",
    "Type": "Integer",
    "Description": "The program-wide maximum parallelism used for operators which haven\u0027t specified a maximum parallelism. The maximum parallelism specifies the upper limit for dynamic scaling and the number of key groups used for partitioned state."
  },
  {
    "Key": "pipeline.name",
    "Default": "(none)",
    "Type": "String",
    "Description": "The job name used for printing and logging."
  },
  {
    "Key": "pipeline.object-reuse",
    "Default": "false",
    "Type": "Boolean",
    "Description": "When enabled objects that Flink internally uses for deserialization and passing data to user-code functions will be reused. Keep in mind that this can lead to bugs when the user-code function of an operation is not aware of this behaviour."
  },
  {
    "Key": "pipeline.operator-chaining",
    "Default": "true",
    "Type": "Boolean",
    "Description": "Operator chaining allows non-shuffle operations to be co-located in the same thread fully avoiding serialization and de-serialization."
  },
  {
    "Key": "pipeline.registered-kryo-types",
    "Default": "(none)",
    "Type": "List\u003cString\u003e",
    "Description": "Semicolon separated list of types to be registered with the serialization stack. If the type is eventually serialized as a POJO, then the type is registered with the POJO serializer. If the type ends up being serialized with Kryo, then it will be registered at Kryo to make sure that only tags are written."
  },
  {
    "Key": "pipeline.registered-pojo-types",
    "Default": "(none)",
    "Type": "List\u003cString\u003e",
    "Description": "Semicolon separated list of types to be registered with the serialization stack. If the type is eventually serialized as a POJO, then the type is registered with the POJO serializer. If the type ends up being serialized with Kryo, then it will be registered at Kryo to make sure that only tags are written."
  },
  {
    "Key": "pipeline.time-characteristic",
    "Default": "ProcessingTime",
    "Type": "Enum Possible values: [ProcessingTime, IngestionTime, EventTime]",
    "Description": "The time characteristic for all created streams, e.g., processingtime, event time, or ingestion time. If you set the characteristic to IngestionTime or EventTime this will set a default watermark update interval of 200 ms. If this is not applicable for your application you should change it using pipeline.auto-watermark-interval."
  },
  {
    "Key": "execution.checkpointing.alignment-timeout",
    "Default": "0 ms",
    "Type": "Duration",
    "Description": "Only relevant if execution.checkpointing.unaligned is enabled. If timeout is 0, checkpoints will always start unaligned. If timeout has a positive value, checkpoints will start aligned. If during checkpointing, checkpoint start delay exceeds this timeout, alignment will timeout and checkpoint barrier will start working as unaligned checkpoint."
  },
  {
    "Key": "execution.checkpointing.externalized-checkpoint-retention",
    "Default": "NO_EXTERNALIZED_CHECKPOINTS",
    "Type": "Enum Possible values: [DELETE_ON_CANCELLATION, RETAIN_ON_CANCELLATION, NO_EXTERNALIZED_CHECKPOINTS]",
    "Description": "Externalized checkpoints write their meta data out to persistent storage and are not automatically cleaned up when the owning job fails or is suspended (terminating with job status JobStatus#FAILED or JobStatus#SUSPENDED). In this case, you have to manually clean up the checkpoint state, both the meta data and actual program state. The mode defines how an externalized checkpoint should be cleaned up on job cancellation. If you choose to retain externalized checkpoints on cancellation you have to handle checkpoint clean up manually when you cancel the job as well (terminating with job status JobStatus#CANCELED). The target directory for externalized checkpoints is configured via state.checkpoints.dir."
  },
  {
    "Key": "execution.checkpointing.interval",
    "Default": "(none)",
    "Type": "Duration",
    "Description": "Gets the interval in which checkpoints are periodically scheduled. This setting defines the base interval. Checkpoint triggering may be delayed by the settings execution.checkpointing.max-concurrent-checkpoints and execution.checkpointing.min-pause"
  },
  {
    "Key": "execution.checkpointing.max-concurrent-checkpoints",
    "Default": "1",
    "Type": "Integer",
    "Description": "The maximum number of checkpoint attempts that may be in progress at the same time. If this value is n, then no checkpoints will be triggered while n checkpoint attempts are currently in flight. For the next checkpoint to be triggered, one checkpoint attempt would need to finish or expire."
  },
  {
    "Key": "execution.checkpointing.min-pause",
    "Default": "0 ms",
    "Type": "Duration",
    "Description": "The minimal pause between checkpointing attempts. This setting defines how soon thecheckpoint coordinator may trigger another checkpoint after it becomes possible to triggeranother checkpoint with respect to the maximum number of concurrent checkpoints(see execution.checkpointing.max-concurrent-checkpoints). If the maximum number of concurrent checkpoints is set to one, this setting makes effectively sure that a minimum amount of time passes where no checkpoint is in progress at all."
  },
  {
    "Key": "execution.checkpointing.mode",
    "Default": "EXACTLY_ONCE",
    "Type": "Enum Possible values: [EXACTLY_ONCE, AT_LEAST_ONCE]",
    "Description": "The checkpointing mode (exactly-once vs. at-least-once)."
  },
  {
    "Key": "execution.checkpointing.prefer-checkpoint-for-recovery",
    "Default": "false",
    "Type": "Boolean",
    "Description": "If enabled, a job recovery should fallback to checkpoint when there is a more recent savepoint."
  },
  {
    "Key": "execution.checkpointing.timeout",
    "Default": "10 min",
    "Type": "Duration",
    "Description": "The maximum time that a checkpoint may take before being discarded."
  },
  {
    "Key": "execution.checkpointing.tolerable-failed-checkpoints",
    "Default": "(none)",
    "Type": "Integer",
    "Description": "The tolerable checkpoint consecutive failure number. If set to 0, that means we do not tolerance any checkpoint failure."
  },
  {
    "Key": "execution.checkpointing.unaligned",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Enables unaligned checkpoints, which greatly reduce checkpointing times under backpressure. Unaligned checkpoints contain data stored in buffers as part of the checkpoint state, which allows checkpoint barriers to overtake these buffers. Thus, the checkpoint duration becomes independent of the current throughput as checkpoint barriers are effectively not embedded into the stream of data anymore. Unaligned checkpoints can only be enabled if execution.checkpointing.mode is EXACTLY_ONCE and if execution.checkpointing.max-concurrent-checkpoints is 1"
  },
  {
    "Key": "execution.checkpointing.unaligned.forced",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Forces unaligned checkpoints, particularly allowing them for iterative jobs."
  },
  {
    "Key": "classloader.check-leaked-classloader",
    "Default": "true",
    "Type": "Boolean",
    "Description": "Fails attempts at loading classes if the user classloader of a job is used after it has terminated. This is usually caused by the classloader being leaked by lingering threads or misbehaving libraries, which may also result in the classloader being used by other jobs. This check should only be disabled if such a leak prevents further jobs from running."
  },
  {
    "Key": "classloader.fail-on-metaspace-oom-error",
    "Default": "true",
    "Type": "Boolean",
    "Description": "Fail Flink JVM processes if \u0027OutOfMemoryError: Metaspace\u0027 is thrown while trying to load a user code class."
  },
  {
    "Key": "classloader.parent-first-patterns.additional",
    "Default": "(none)",
    "Type": "String",
    "Description": "A (semicolon-separated) list of patterns that specifies which classes should always be resolved through the parent ClassLoader first. A pattern is a simple prefix that is checked against the fully qualified class name. These patterns are appended to \"classloader.parent-first-patterns.default\"."
  },
  {
    "Key": "classloader.parent-first-patterns.default",
    "Default": "\"java.;scala.;org.apache.flink.;com.esotericsoftware.kryo;org.apache.hadoop.;javax.annotation.;org.slf4j;org.apache.log4j;org.apache.logging;org.apache.commons.logging;ch.qos.logback;org.xml;javax.xml;org.apache.xerces;org.w3c\"",
    "Type": "String",
    "Description": "A (semicolon-separated) list of patterns that specifies which classes should always be resolved through the parent ClassLoader first. A pattern is a simple prefix that is checked against the fully qualified class name. This setting should generally not be modified. To add another pattern we recommend to use \"classloader.parent-first-patterns.additional\" instead."
  },
  {
    "Key": "classloader.resolve-order",
    "Default": "\"child-first\"",
    "Type": "String",
    "Description": "Defines the class resolution strategy when loading classes from user code, meaning whether to first check the user code jar (\"child-first\") or the application classpath (\"parent-first\"). The default settings indicate to load classes first from the user code jar, which means that user code jars can include and load different dependencies than Flink uses (transitively)."
  },
  {
    "Key": "jmx.server.port",
    "Default": "(none)",
    "Type": "String",
    "Description": "The port range for the JMX server to start the registry. The port config can be a single port: \"9123\", a range of ports: \"50100-50200\", or a list of ranges and ports: \"50100-50200,50300-50400,51234\". This option overrides metrics.reporter.*.port option."
  },
  {
    "Key": "state.storage.fs.memory-threshold",
    "Default": "20 kb",
    "Type": "MemorySize",
    "Description": "The minimum size of state data files. All state chunks smaller than that are stored inline in the root checkpoint metadata file. The max memory threshold for this configuration is 1MB."
  },
  {
    "Key": "state.storage.fs.write-buffer-size",
    "Default": "4096",
    "Type": "Integer",
    "Description": "The default size of the write buffer for the checkpoint streams that write to file systems. The actual write buffer size is determined to be the maximum of the value of this option and option \u0027state.storage.fs.memory-threshold\u0027."
  },
  {
    "Key": "state.backend.latency-track.history-size",
    "Default": "128",
    "Type": "Integer",
    "Description": "Defines the number of measured latencies to maintain at each state access operation."
  },
  {
    "Key": "state.backend.latency-track.keyed-state-enabled",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Whether to track latency of keyed state operations, e.g value state put/get/clear."
  },
  {
    "Key": "state.backend.latency-track.sample-interval",
    "Default": "100",
    "Type": "Integer",
    "Description": "The sample interval of latency track once \u0027state.backend.latency-track.keyed-state-enabled\u0027 is enabled. The default value is 100, which means we would track the latency every 100 access requests."
  },
  {
    "Key": "state.backend.latency-track.state-name-as-variable",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Whether to expose state name as a variable if tracking latency."
  },
  {
    "Key": "state.backend.rocksdb.checkpoint.transfer.thread.num",
    "Default": "4",
    "Type": "Integer",
    "Description": "The number of threads (per stateful operator) used to transfer (download and upload) files in RocksDBStateBackend."
  },
  {
    "Key": "state.backend.rocksdb.localdir",
    "Default": "(none)",
    "Type": "String",
    "Description": "The local directory (on the TaskManager) where RocksDB puts its files."
  },
  {
    "Key": "state.backend.rocksdb.options-factory",
    "Default": "\"org.apache.flink.contrib.streaming.state.DefaultConfigurableOptionsFactory\"",
    "Type": "String",
    "Description": "The options factory class for RocksDB to create DBOptions and ColumnFamilyOptions. The default options factory is org.apache.flink.contrib.streaming.state.DefaultConfigurableOptionsFactory, and it would read the configured options which provided in \u0027RocksDBConfigurableOptions\u0027."
  },
  {
    "Key": "state.backend.rocksdb.predefined-options",
    "Default": "\"DEFAULT\"",
    "Type": "String",
    "Description": "The predefined settings for RocksDB DBOptions and ColumnFamilyOptions by Flink community. Current supported candidate predefined-options are DEFAULT, SPINNING_DISK_OPTIMIZED, SPINNING_DISK_OPTIMIZED_HIGH_MEM or FLASH_SSD_OPTIMIZED. Note that user customized options and options from the RocksDBOptionsFactory are applied on top of these predefined ones."
  },
  {
    "Key": "state.backend.rocksdb.block.blocksize",
    "Default": "(none)",
    "Type": "MemorySize",
    "Description": "The approximate size (in bytes) of user data packed per block. RocksDB has default blocksize as \u00274KB\u0027."
  },
  {
    "Key": "state.backend.rocksdb.block.cache-size",
    "Default": "(none)",
    "Type": "MemorySize",
    "Description": "The amount of the cache for data blocks in RocksDB. RocksDB has default block-cache size as \u00278MB\u0027."
  },
  {
    "Key": "state.backend.rocksdb.block.metadata-blocksize",
    "Default": "(none)",
    "Type": "MemorySize",
    "Description": "Approximate size of partitioned metadata packed per block. Currently applied to indexes block when partitioned index/filters option is enabled. RocksDB has default metadata blocksize as \u00274KB\u0027."
  },
  {
    "Key": "state.backend.rocksdb.compaction.level.max-size-level-base",
    "Default": "(none)",
    "Type": "MemorySize",
    "Description": "The upper-bound of the total size of level base files in bytes. RocksDB has default configuration as \u0027256MB\u0027."
  },
  {
    "Key": "state.backend.rocksdb.compaction.level.target-file-size-base",
    "Default": "(none)",
    "Type": "MemorySize",
    "Description": "The target file size for compaction, which determines a level-1 file size. RocksDB has default configuration as \u002764MB\u0027."
  },
  {
    "Key": "state.backend.rocksdb.compaction.level.use-dynamic-size",
    "Default": "(none)",
    "Type": "Boolean",
    "Description": "If true, RocksDB will pick target size of each level dynamically. From an empty DB, RocksDB would make last level the base level, which means merging L0 data into the last level, until it exceeds max_bytes_for_level_base. And then repeat this process for second last level and so on. RocksDB has default configuration as \u0027false\u0027. For more information, please refer to RocksDB\u0027s doc."
  },
  {
    "Key": "state.backend.rocksdb.compaction.style",
    "Default": "(none)",
    "Type": "Enum Possible values: [LEVEL, UNIVERSAL, FIFO]",
    "Description": "The specified compaction style for DB. Candidate compaction style is LEVEL, FIFO or UNIVERSAL, and RocksDB choose \u0027LEVEL\u0027 as default style."
  },
  {
    "Key": "state.backend.rocksdb.files.open",
    "Default": "(none)",
    "Type": "Integer",
    "Description": "The maximum number of open files (per stateful operator) that can be used by the DB, \u0027-1\u0027 means no limit. RocksDB has default configuration as \u0027-1\u0027."
  },
  {
    "Key": "state.backend.rocksdb.log.level",
    "Default": "(none)",
    "Type": "Enum Possible values: [DEBUG_LEVEL, INFO_LEVEL, WARN_LEVEL, ERROR_LEVEL, FATAL_LEVEL, HEADER_LEVEL, NUM_INFO_LOG_LEVELS]",
    "Description": "The specified log level for DB. Candidate log level is DEBUG_LEVEL, INFO_LEVEL, WARN_LEVEL, ERROR_LEVEL, FATAL_LEVEL, HEADER_LEVEL or NUM_INFO_LOG_LEVELS, and Flink choose \u0027HEADER_LEVEL\u0027 as default style. Note: RocksDB logs will not be output to TaskManager logs, and there is no rolling strategy. If the Flink task runs for a long time, it may lead to uncontrolled disk space usage. There is no need to modify the RocksDB log level, unless troubleshooting RocksDB."
  },
  {
    "Key": "state.backend.rocksdb.thread.num",
    "Default": "(none)",
    "Type": "Integer",
    "Description": "The maximum number of concurrent background flush and compaction jobs (per stateful operator). RocksDB has default configuration as \u00272\u0027."
  },
  {
    "Key": "state.backend.rocksdb.write-batch-size",
    "Default": "2 mb",
    "Type": "MemorySize",
    "Description": "The max size of the consumed memory for RocksDB batch write, will flush just based on item count if this config set to 0."
  },
  {
    "Key": "state.backend.rocksdb.writebuffer.count",
    "Default": "(none)",
    "Type": "Integer",
    "Description": "The maximum number of write buffers that are built up in memory. RocksDB has default configuration as \u00272\u0027."
  },
  {
    "Key": "state.backend.rocksdb.writebuffer.number-to-merge",
    "Default": "(none)",
    "Type": "Integer",
    "Description": "The minimum number of write buffers that will be merged together before writing to storage. RocksDB has default configuration as \u00271\u0027."
  },
  {
    "Key": "state.backend.rocksdb.writebuffer.size",
    "Default": "(none)",
    "Type": "MemorySize",
    "Description": "The amount of data built up in memory (backed by an unsorted log on disk) before converting to a sorted on-disk files. RocksDB has default writebuffer size as \u002764MB\u0027."
  },
  {
    "Key": "cluster.io-pool.size",
    "Default": "(none)",
    "Type": "Integer",
    "Description": "The size of the IO executor pool used by the cluster to execute blocking IO operations (Master as well as TaskManager processes). By default it will use 4 * the number of CPU cores (hardware contexts) that the cluster process has access to. Increasing the pool size allows to run more IO operations concurrently."
  },
  {
    "Key": "cluster.registration.error-delay",
    "Default": "10000",
    "Type": "Long",
    "Description": "The pause made after an registration attempt caused an exception (other than timeout) in milliseconds."
  },
  {
    "Key": "cluster.registration.initial-timeout",
    "Default": "100",
    "Type": "Long",
    "Description": "Initial registration timeout between cluster components in milliseconds."
  },
  {
    "Key": "cluster.registration.max-timeout",
    "Default": "30000",
    "Type": "Long",
    "Description": "Maximum registration timeout between cluster components in milliseconds."
  },
  {
    "Key": "cluster.registration.refused-registration-delay",
    "Default": "30000",
    "Type": "Long",
    "Description": "The pause made after the registration attempt was refused in milliseconds."
  },
  {
    "Key": "cluster.services.shutdown-timeout",
    "Default": "30000",
    "Type": "Long",
    "Description": "The shutdown timeout for cluster services like executors in milliseconds."
  },
  {
    "Key": "heartbeat.interval",
    "Default": "10000",
    "Type": "Long",
    "Description": "Time interval for requesting heartbeat from sender side."
  },
  {
    "Key": "heartbeat.timeout",
    "Default": "50000",
    "Type": "Long",
    "Description": "Timeout for requesting and receiving heartbeat for both sender and receiver sides."
  },
  {
    "Key": "jobmanager.execution.failover-strategy",
    "Default": "\"region\"",
    "Type": "String",
    "Description": "This option specifies how the job computation recovers from task failures. Accepted values are: \u0027full\u0027: Restarts all tasks to recover the job. \u0027region\u0027: Restarts all tasks that could be affected by the task failure. More details can be found here."
  },
  {
    "Key": "cluster.intercept-user-system-exit",
    "Default": "DISABLED",
    "Type": "Enum Possible values: [DISABLED, LOG, THROW]",
    "Description": "Flag to check user code exiting system by terminating JVM (e.g., System.exit()) DISABLED - Flink is not monitoring or intercepting calls to System.exit() LOG - Log exit attempt with stack trace but still allowing exit to be performed THROW - Throw exception when exit is attempted disallowing JVM termination Note that this configuration option can interfere with cluster.processes.halt-on-fatal-error: In intercepted user-code, a call to System.exit() will not cause the JVM to halt, when THROW is configured."
  },
  {
    "Key": "cluster.processes.halt-on-fatal-error",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Whether processes should halt on fatal errors instead of performing a graceful shutdown. In some environments (e.g. Java 8 with the G1 garbage collector), a regular graceful shutdown can lead to a JVM deadlock. See FLINK-16510 for details."
  },
  {
    "Key": "cluster.evenly-spread-out-slots",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Enable the slot spread out allocation strategy. This strategy tries to spread out the slots evenly across all available TaskExecutors."
  },
  {
    "Key": "jobmanager.adaptive-scheduler.min-parallelism-increase",
    "Default": "1",
    "Type": "Integer",
    "Description": "Configure the minimum increase in parallelism for a job to scale up."
  },
  {
    "Key": "jobmanager.adaptive-scheduler.resource-stabilization-timeout",
    "Default": "10 s",
    "Type": "Duration",
    "Description": "The resource stabilization timeout defines the time the JobManager will wait if fewer than the desired but sufficient resources are available. The timeout starts once sufficient resources for running the job are available. Once this timeout has passed, the job will start executing with the available resources. If scheduler-mode is configured to REACTIVE, this configuration value will default to 0, so that jobs are starting immediately with the available resources."
  },
  {
    "Key": "jobmanager.adaptive-scheduler.resource-wait-timeout",
    "Default": "5 min",
    "Type": "Duration",
    "Description": "The maximum time the JobManager will wait to acquire all required resources after a job submission or restart. Once elapsed it will try to run the job with a lower parallelism, or fail if the minimum amount of resources could not be acquired. Increasing this value will make the cluster more resilient against temporary resources shortages (e.g., there is more time for a failed TaskManager to be restarted). Setting a negative duration will disable the resource timeout: The JobManager will wait indefinitely for resources to appear. If scheduler-mode is configured to REACTIVE, this configuration value will default to a negative value to disable the resource timeout."
  },
  {
    "Key": "scheduler-mode",
    "Default": "(none)",
    "Type": "Enum Possible values: [REACTIVE]",
    "Description": "Determines the mode of the scheduler. Note that scheduler-mode\u003dREACTIVE is only supported by standalone application deployments, not by active resource managers (YARN, Kubernetes) or session clusters."
  },
  {
    "Key": "slot.idle.timeout",
    "Default": "50000",
    "Type": "Long",
    "Description": "The timeout in milliseconds for a idle slot in Slot Pool."
  },
  {
    "Key": "slot.request.timeout",
    "Default": "300000",
    "Type": "Long",
    "Description": "The timeout in milliseconds for requesting a slot from Slot Pool."
  },
  {
    "Key": "slotmanager.number-of-slots.max",
    "Default": "2147483647",
    "Type": "Integer",
    "Description": "Defines the maximum number of slots that the Flink cluster allocates. This configuration option is meant for limiting the resource consumption for batch workloads. It is not recommended to configure this option for streaming workloads, which may fail if there are not enough slots. Note that this configuration option does not take effect for standalone clusters, where how many slots are allocated is not controlled by Flink."
  },
  {
    "Key": "high-availability.jobmanager.port",
    "Default": "\"0\"",
    "Type": "String",
    "Description": "The port (range) used by the Flink Master for its RPC connections in highly-available setups. In highly-available setups, this value is used instead of \u0027jobmanager.rpc.port\u0027.A value of \u00270\u0027 means that a random free port is chosen. TaskManagers discover this port through the high-availability services (leader election), so a random port or a port range works without requiring any additional means of service discovery."
  },
  {
    "Key": "high-availability.zookeeper.client.acl",
    "Default": "\"open\"",
    "Type": "String",
    "Description": "Defines the ACL (open|creator) to be configured on ZK node. The configuration value can be set to “creator” if the ZooKeeper server configuration has the “authProvider” property mapped to use SASLAuthenticationProvider and the cluster is configured to run in secure mode (Kerberos)."
  },
  {
    "Key": "high-availability.zookeeper.client.connection-timeout",
    "Default": "15000",
    "Type": "Integer",
    "Description": "Defines the connection timeout for ZooKeeper in ms."
  },
  {
    "Key": "high-availability.zookeeper.client.max-retry-attempts",
    "Default": "3",
    "Type": "Integer",
    "Description": "Defines the number of connection retries before the client gives up."
  },
  {
    "Key": "high-availability.zookeeper.client.retry-wait",
    "Default": "5000",
    "Type": "Integer",
    "Description": "Defines the pause between consecutive retries in ms."
  },
  {
    "Key": "high-availability.zookeeper.client.session-timeout",
    "Default": "60000",
    "Type": "Integer",
    "Description": "Defines the session timeout for the ZooKeeper session in ms."
  },
  {
    "Key": "high-availability.zookeeper.path.checkpoint-counter",
    "Default": "\"/checkpoint-counter\"",
    "Type": "String",
    "Description": "ZooKeeper root path (ZNode) for checkpoint counters."
  },
  {
    "Key": "high-availability.zookeeper.path.checkpoints",
    "Default": "\"/checkpoints\"",
    "Type": "String",
    "Description": "ZooKeeper root path (ZNode) for completed checkpoints."
  },
  {
    "Key": "high-availability.zookeeper.path.jobgraphs",
    "Default": "\"/jobgraphs\"",
    "Type": "String",
    "Description": "ZooKeeper root path (ZNode) for job graphs"
  },
  {
    "Key": "high-availability.zookeeper.path.latch",
    "Default": "\"/leaderlatch\"",
    "Type": "String",
    "Description": "Defines the znode of the leader latch which is used to elect the leader."
  },
  {
    "Key": "high-availability.zookeeper.path.leader",
    "Default": "\"/leader\"",
    "Type": "String",
    "Description": "Defines the znode of the leader which contains the URL to the leader and the current leader session ID."
  },
  {
    "Key": "high-availability.zookeeper.path.mesos-workers",
    "Default": "\"/mesos-workers\"",
    "Type": "String",
    "Description": "The ZooKeeper root path for persisting the Mesos worker information."
  },
  {
    "Key": "high-availability.zookeeper.path.running-registry",
    "Default": "\"/running_job_registry/\"",
    "Type": "String",
    "Description": ""
  },
  {
    "Key": "high-availability.kubernetes.leader-election.lease-duration",
    "Default": "15 s",
    "Type": "Duration",
    "Description": "Define the lease duration for the Kubernetes leader election. The leader will continuously renew its lease time to indicate its existence. And the followers will do a lease checking against the current time. \"renewTime + leaseDuration \u003e now\" means the leader is alive."
  },
  {
    "Key": "high-availability.kubernetes.leader-election.renew-deadline",
    "Default": "15 s",
    "Type": "Duration",
    "Description": "Defines the deadline duration when the leader tries to renew the lease. The leader will give up its leadership if it cannot successfully renew the lease in the given time."
  },
  {
    "Key": "high-availability.kubernetes.leader-election.retry-period",
    "Default": "5 s",
    "Type": "Duration",
    "Description": "Defines the pause duration between consecutive retries. All the contenders, including the current leader and all other followers, periodically try to acquire/renew the leadership if possible at this interval."
  },
  {
    "Key": "security.ssl.internal.close-notify-flush-timeout",
    "Default": "-1",
    "Type": "Integer",
    "Description": "The timeout (in ms) for flushing the `close_notify` that was triggered by closing a channel. If the `close_notify` was not flushed in the given timeout the channel will be closed forcibly. (-1 \u003d use system default)"
  },
  {
    "Key": "security.ssl.internal.handshake-timeout",
    "Default": "-1",
    "Type": "Integer",
    "Description": "The timeout (in ms) during SSL handshake. (-1 \u003d use system default)"
  },
  {
    "Key": "security.ssl.internal.session-cache-size",
    "Default": "-1",
    "Type": "Integer",
    "Description": "The size of the cache used for storing SSL session objects. According to here, you should always set this to an appropriate number to not run into a bug with stalling IO threads during garbage collection. (-1 \u003d use system default)."
  },
  {
    "Key": "security.ssl.internal.session-timeout",
    "Default": "-1",
    "Type": "Integer",
    "Description": "The timeout (in ms) for the cached SSL session objects. (-1 \u003d use system default)"
  },
  {
    "Key": "security.ssl.provider",
    "Default": "\"JDK\"",
    "Type": "String",
    "Description": "The SSL engine provider to use for the ssl transport: JDK: default Java-based SSL engine OPENSSL: openSSL-based SSL engine using system libraries OPENSSL is based on netty-tcnative and comes in two flavours: dynamically linked: This will use your system\u0027s openSSL libraries (if compatible) and requires opt/flink-shaded-netty-tcnative-dynamic-*.jar to be copied to lib/ statically linked: Due to potential licensing issues with openSSL (see LEGAL-393), we cannot ship pre-built libraries. However, you can build the required library yourself and put it into lib/: git clone https://github.com/apache/flink-shaded.git \u0026\u0026 cd flink-shaded \u0026\u0026 mvn clean package -Pinclude-netty-tcnative-static -pl flink-shaded-netty-tcnative-static"
  },
  {
    "Key": "rest.await-leader-timeout",
    "Default": "30000",
    "Type": "Long",
    "Description": "The time in ms that the client waits for the leader address, e.g., Dispatcher or WebMonitorEndpoint"
  },
  {
    "Key": "rest.client.max-content-length",
    "Default": "104857600",
    "Type": "Integer",
    "Description": "The maximum content length in bytes that the client will handle."
  },
  {
    "Key": "rest.connection-timeout",
    "Default": "15000",
    "Type": "Long",
    "Description": "The maximum time in ms for the client to establish a TCP connection."
  },
  {
    "Key": "rest.flamegraph.cleanup-interval",
    "Default": "10 min",
    "Type": "Duration",
    "Description": "Time after which cached stats are cleaned up if not accessed. It can be specified using notation: \"100 s\", \"10 m\"."
  },
  {
    "Key": "rest.flamegraph.delay-between-samples",
    "Default": "50 ms",
    "Type": "Duration",
    "Description": "Delay between individual stack trace samples taken for building a FlameGraph. It can be specified using notation: \"100 ms\", \"1 s\"."
  },
  {
    "Key": "rest.flamegraph.enabled",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Enables the experimental flame graph feature."
  },
  {
    "Key": "rest.flamegraph.num-samples",
    "Default": "100",
    "Type": "Integer",
    "Description": "Number of samples to take to build a FlameGraph."
  },
  {
    "Key": "rest.flamegraph.refresh-interval",
    "Default": "1 min",
    "Type": "Duration",
    "Description": "Time after which available stats are deprecated and need to be refreshed (by resampling). It can be specified using notation: \"30 s\", \"1 m\"."
  },
  {
    "Key": "rest.flamegraph.stack-depth",
    "Default": "100",
    "Type": "Integer",
    "Description": "Maximum depth of stack traces used to create FlameGraphs."
  },
  {
    "Key": "rest.idleness-timeout",
    "Default": "300000",
    "Type": "Long",
    "Description": "The maximum time in ms for a connection to stay idle before failing."
  },
  {
    "Key": "rest.retry.delay",
    "Default": "3000",
    "Type": "Long",
    "Description": "The time in ms that the client waits between retries (See also `rest.retry.max-attempts`)."
  },
  {
    "Key": "rest.retry.max-attempts",
    "Default": "20",
    "Type": "Integer",
    "Description": "The number of retries the client will attempt if a retryable operations fails."
  },
  {
    "Key": "rest.server.max-content-length",
    "Default": "104857600",
    "Type": "Integer",
    "Description": "The maximum content length in bytes that the server will handle."
  },
  {
    "Key": "rest.server.numThreads",
    "Default": "4",
    "Type": "Integer",
    "Description": "The number of threads for the asynchronous processing of requests."
  },
  {
    "Key": "rest.server.thread-priority",
    "Default": "5",
    "Type": "Integer",
    "Description": "Thread priority of the REST server\u0027s executor for processing asynchronous requests. Lowering the thread priority will give Flink\u0027s main components more CPU time whereas increasing will allocate more time for the REST server\u0027s processing."
  },
  {
    "Key": "web.access-control-allow-origin",
    "Default": "\"*\"",
    "Type": "String",
    "Description": "Access-Control-Allow-Origin header for all responses from the web-frontend."
  },
  {
    "Key": "web.checkpoints.history",
    "Default": "10",
    "Type": "Integer",
    "Description": "Number of checkpoints to remember for recent history."
  },
  {
    "Key": "web.exception-history-size",
    "Default": "16",
    "Type": "Integer",
    "Description": "The maximum number of failures collected by the exception history per job."
  },
  {
    "Key": "web.history",
    "Default": "5",
    "Type": "Integer",
    "Description": "Number of archived jobs for the JobManager."
  },
  {
    "Key": "web.log.path",
    "Default": "(none)",
    "Type": "String",
    "Description": "Path to the log file (may be in /log for standalone but under log directory when using YARN)."
  },
  {
    "Key": "web.refresh-interval",
    "Default": "3000",
    "Type": "Long",
    "Description": "Refresh interval for the web-frontend in milliseconds."
  },
  {
    "Key": "web.submit.enable",
    "Default": "true",
    "Type": "Boolean",
    "Description": "Flag indicating whether jobs can be uploaded and run from the web-frontend."
  },
  {
    "Key": "web.timeout",
    "Default": "600000",
    "Type": "Long",
    "Description": "Timeout for asynchronous operations by the web monitor in milliseconds."
  },
  {
    "Key": "web.tmpdir",
    "Default": "System.getProperty(\"java.io.tmpdir\")",
    "Type": "String",
    "Description": "Flink web directory which is used by the webmonitor."
  },
  {
    "Key": "web.upload.dir",
    "Default": "(none)",
    "Type": "String",
    "Description": "Directory for uploading the job jars. If not specified a dynamic directory will be used under the directory specified by JOB_MANAGER_WEB_TMPDIR_KEY."
  },
  {
    "Key": "jobmanager.adaptive-scheduler.min-parallelism-increase",
    "Default": "1",
    "Type": "Integer",
    "Description": "Configure the minimum increase in parallelism for a job to scale up."
  },
  {
    "Key": "jobmanager.adaptive-scheduler.resource-stabilization-timeout",
    "Default": "10 s",
    "Type": "Duration",
    "Description": "The resource stabilization timeout defines the time the JobManager will wait if fewer than the desired but sufficient resources are available. The timeout starts once sufficient resources for running the job are available. Once this timeout has passed, the job will start executing with the available resources. If scheduler-mode is configured to REACTIVE, this configuration value will default to 0, so that jobs are starting immediately with the available resources."
  },
  {
    "Key": "jobmanager.adaptive-scheduler.resource-wait-timeout",
    "Default": "5 min",
    "Type": "Duration",
    "Description": "The maximum time the JobManager will wait to acquire all required resources after a job submission or restart. Once elapsed it will try to run the job with a lower parallelism, or fail if the minimum amount of resources could not be acquired. Increasing this value will make the cluster more resilient against temporary resources shortages (e.g., there is more time for a failed TaskManager to be restarted). Setting a negative duration will disable the resource timeout: The JobManager will wait indefinitely for resources to appear. If scheduler-mode is configured to REACTIVE, this configuration value will default to a negative value to disable the resource timeout."
  },
  {
    "Key": "jobmanager.archive.fs.dir",
    "Default": "(none)",
    "Type": "String",
    "Description": "Dictionary for JobManager to store the archives of completed jobs."
  },
  {
    "Key": "jobmanager.execution.attempts-history-size",
    "Default": "16",
    "Type": "Integer",
    "Description": "The maximum number of prior execution attempts kept in history."
  },
  {
    "Key": "jobmanager.execution.failover-strategy",
    "Default": "\"region\"",
    "Type": "String",
    "Description": "This option specifies how the job computation recovers from task failures. Accepted values are: \u0027full\u0027: Restarts all tasks to recover the job. \u0027region\u0027: Restarts all tasks that could be affected by the task failure. More details can be found here."
  },
  {
    "Key": "jobmanager.retrieve-taskmanager-hostname",
    "Default": "true",
    "Type": "Boolean",
    "Description": "Flag indicating whether JobManager would retrieve canonical host name of TaskManager during registration. If the option is set to \"false\", TaskManager registration with JobManager could be faster, since no reverse DNS lookup is performed. However, local input split assignment (such as for HDFS files) may be impacted."
  },
  {
    "Key": "jobmanager.rpc.address",
    "Default": "(none)",
    "Type": "String",
    "Description": "The config parameter defining the network address to connect to for communication with the job manager. This value is only interpreted in setups where a single JobManager with static name or address exists (simple standalone setups, or container setups with dynamic service name resolution). It is not used in many high-availability setups, when a leader-election service (like ZooKeeper) is used to elect and discover the JobManager leader from potentially multiple standby JobManagers."
  },
  {
    "Key": "jobmanager.rpc.port",
    "Default": "6123",
    "Type": "Integer",
    "Description": "The config parameter defining the network port to connect to for communication with the job manager. Like jobmanager.rpc.address, this value is only interpreted in setups where a single JobManager with static name/address and port exists (simple standalone setups, or container setups with dynamic service name resolution). This config option is not used in many high-availability setups, when a leader-election service (like ZooKeeper) is used to elect and discover the JobManager leader from potentially multiple standby JobManagers."
  },
  {
    "Key": "jobstore.cache-size",
    "Default": "52428800",
    "Type": "Long",
    "Description": "The job store cache size in bytes which is used to keep completed jobs in memory."
  },
  {
    "Key": "jobstore.expiration-time",
    "Default": "3600",
    "Type": "Long",
    "Description": "The time in seconds after which a completed job expires and is purged from the job store."
  },
  {
    "Key": "jobstore.max-capacity",
    "Default": "2147483647",
    "Type": "Integer",
    "Description": "The max number of completed jobs that can be kept in the job store."
  },
  {
    "Key": "web.exception-history-size",
    "Default": "16",
    "Type": "Integer",
    "Description": "The maximum number of failures collected by the exception history per job."
  },
  {
    "Key": "blob.client.connect.timeout",
    "Default": "0",
    "Type": "Integer",
    "Description": "The connection timeout in milliseconds for the blob client."
  },
  {
    "Key": "blob.client.socket.timeout",
    "Default": "300000",
    "Type": "Integer",
    "Description": "The socket timeout in milliseconds for the blob client."
  },
  {
    "Key": "blob.fetch.backlog",
    "Default": "1000",
    "Type": "Integer",
    "Description": "The config parameter defining the desired backlog of BLOB fetches on the JobManager.Note that the operating system usually enforces an upper limit on the backlog size based on the SOMAXCONN setting."
  },
  {
    "Key": "blob.fetch.num-concurrent",
    "Default": "50",
    "Type": "Integer",
    "Description": "The config parameter defining the maximum number of concurrent BLOB fetches that the JobManager serves."
  },
  {
    "Key": "blob.fetch.retries",
    "Default": "5",
    "Type": "Integer",
    "Description": "The config parameter defining number of retires for failed BLOB fetches."
  },
  {
    "Key": "blob.offload.minsize",
    "Default": "1048576",
    "Type": "Integer",
    "Description": "The minimum size for messages to be offloaded to the BlobServer."
  },
  {
    "Key": "blob.server.port",
    "Default": "\"0\"",
    "Type": "String",
    "Description": "The config parameter defining the server port of the blob service."
  },
  {
    "Key": "blob.service.cleanup.interval",
    "Default": "3600",
    "Type": "Long",
    "Description": "Cleanup interval of the blob caches at the task managers (in seconds)."
  },
  {
    "Key": "blob.service.ssl.enabled",
    "Default": "true",
    "Type": "Boolean",
    "Description": "Flag to override ssl support for the blob service transport."
  },
  {
    "Key": "blob.storage.directory",
    "Default": "(none)",
    "Type": "String",
    "Description": "The config parameter defining the storage directory to be used by the blob server."
  },
  {
    "Key": "resourcemanager.job.timeout",
    "Default": "\"5 minutes\"",
    "Type": "String",
    "Description": "Timeout for jobs which don\u0027t have a job manager as leader assigned."
  },
  {
    "Key": "resourcemanager.rpc.port",
    "Default": "0",
    "Type": "Integer",
    "Description": "Defines the network port to connect to for communication with the resource manager. By default, the port of the JobManager, because the same ActorSystem is used. Its not possible to use this configuration key to define port ranges."
  },
  {
    "Key": "resourcemanager.standalone.start-up-time",
    "Default": "-1",
    "Type": "Long",
    "Description": "Time in milliseconds of the start-up period of a standalone cluster. During this time, resource manager of the standalone cluster expects new task executors to be registered, and will not fail slot requests that can not be satisfied by any current registered slots. After this time, it will fail pending and new coming requests immediately that can not be satisfied by registered slots. If not set, slot.request.timeout will be used by default."
  },
  {
    "Key": "resourcemanager.start-worker.max-failure-rate",
    "Default": "10.0",
    "Type": "Double",
    "Description": "The maximum number of start worker failures (Native Kubernetes / Yarn / Mesos) per minute before pausing requesting new workers. Once the threshold is reached, subsequent worker requests will be postponed to after a configured retry interval (\u0027resourcemanager.start-worker.retry-interval\u0027)."
  },
  {
    "Key": "resourcemanager.start-worker.retry-interval",
    "Default": "3 s",
    "Type": "Duration",
    "Description": "The time to wait before requesting new workers (Native Kubernetes / Yarn / Mesos) once the max failure rate of starting workers (\u0027resourcemanager.start-worker.max-failure-rate\u0027) is reached."
  },
  {
    "Key": "resourcemanager.taskmanager-registration.timeout",
    "Default": "5 min",
    "Type": "Duration",
    "Description": "Timeout for TaskManagers to register at the active resource managers. If exceeded, active resource manager will release and try to re-request the resource for the worker. If not configured, fallback to \u0027taskmanager.registration.timeout\u0027."
  },
  {
    "Key": "resourcemanager.taskmanager-timeout",
    "Default": "30000",
    "Type": "Long",
    "Description": "The timeout for an idle task manager to be released."
  },
  {
    "Key": "slotmanager.number-of-slots.max",
    "Default": "2147483647",
    "Type": "Integer",
    "Description": "Defines the maximum number of slots that the Flink cluster allocates. This configuration option is meant for limiting the resource consumption for batch workloads. It is not recommended to configure this option for streaming workloads, which may fail if there are not enough slots. Note that this configuration option does not take effect for standalone clusters, where how many slots are allocated is not controlled by Flink."
  },
  {
    "Key": "slotmanager.redundant-taskmanager-num",
    "Default": "0",
    "Type": "Integer",
    "Description": "The number of redundant task managers. Redundant task managers are extra task managers started by Flink, in order to speed up job recovery in case of failures due to task manager lost. Note that this feature is available only to the active deployments (native K8s, Yarn and Mesos)."
  },
  {
    "Key": "task.cancellation.interval",
    "Default": "30000",
    "Type": "Long",
    "Description": "Time interval between two successive task cancellation attempts in milliseconds."
  },
  {
    "Key": "task.cancellation.timeout",
    "Default": "180000",
    "Type": "Long",
    "Description": "Timeout in milliseconds after which a task cancellation times out and leads to a fatal TaskManager error. A value of 0 deactivates the watch dog. Notice that a task cancellation is different from both a task failure and a clean shutdown. Task cancellation timeout only applies to task cancellation and does not apply to task closing/clean-up caused by a task failure or a clean shutdown."
  },
  {
    "Key": "task.cancellation.timers.timeout",
    "Default": "7500",
    "Type": "Long",
    "Description": "Time we wait for the timers in milliseconds to finish all pending timer threads when the stream task is cancelled."
  },
  {
    "Key": "taskmanager.data.port",
    "Default": "0",
    "Type": "Integer",
    "Description": "The task manager’s external port used for data exchange operations."
  },
  {
    "Key": "taskmanager.data.ssl.enabled",
    "Default": "true",
    "Type": "Boolean",
    "Description": "Enable SSL support for the taskmanager data transport. This is applicable only when the global flag for internal SSL (security.ssl.internal.enabled) is set to true"
  },
  {
    "Key": "taskmanager.debug.memory.log",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Flag indicating whether to start a thread, which repeatedly logs the memory usage of the JVM."
  },
  {
    "Key": "taskmanager.debug.memory.log-interval",
    "Default": "5000",
    "Type": "Long",
    "Description": "The interval (in ms) for the log thread to log the current memory usage."
  },
  {
    "Key": "taskmanager.host",
    "Default": "(none)",
    "Type": "String",
    "Description": "The external address of the network interface where the TaskManager is exposed. Because different TaskManagers need different values for this option, usually it is specified in an additional non-shared TaskManager-specific config file."
  },
  {
    "Key": "taskmanager.jvm-exit-on-oom",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Whether to kill the TaskManager when the task thread throws an OutOfMemoryError."
  },
  {
    "Key": "taskmanager.memory.segment-size",
    "Default": "32 kb",
    "Type": "MemorySize",
    "Description": "Size of memory buffers used by the network stack and the memory manager."
  },
  {
    "Key": "taskmanager.network.bind-policy",
    "Default": "\"ip\"",
    "Type": "String",
    "Description": "The automatic address binding policy used by the TaskManager if \"taskmanager.host\" is not set. The value should be one of the following: \"name\" - uses hostname as binding address \"ip\" - uses host\u0027s ip address as binding address"
  },
  {
    "Key": "taskmanager.numberOfTaskSlots",
    "Default": "1",
    "Type": "Integer",
    "Description": "The number of parallel operator or user function instances that a single TaskManager can run. If this value is larger than 1, a single TaskManager takes multiple instances of a function or operator. That way, the TaskManager can utilize multiple CPU cores, but at the same time, the available memory is divided between the different operator or function instances. This value is typically proportional to the number of physical CPU cores that the TaskManager\u0027s machine has (e.g., equal to the number of cores, or half the number of cores)."
  },
  {
    "Key": "taskmanager.registration.timeout",
    "Default": "5 min",
    "Type": "Duration",
    "Description": "Defines the timeout for the TaskManager registration. If the duration is exceeded without a successful registration, then the TaskManager terminates."
  },
  {
    "Key": "taskmanager.resource-id",
    "Default": "(none)",
    "Type": "String",
    "Description": "The TaskManager\u0027s ResourceID. If not configured, the ResourceID will be generated with the \"RpcAddress:RpcPort\" and a 6-character random string. Notice that this option is not valid in Yarn / Mesos and Native Kubernetes mode."
  },
  {
    "Key": "taskmanager.rpc.port",
    "Default": "\"0\"",
    "Type": "String",
    "Description": "The external RPC port where the TaskManager is exposed. Accepts a list of ports (“50100,50101”), ranges (“50100-50200”) or a combination of both. It is recommended to set a range of ports to avoid collisions when multiple TaskManagers are running on the same machine."
  },
  {
    "Key": "taskmanager.slot.timeout",
    "Default": "10 s",
    "Type": "Duration",
    "Description": "Timeout used for identifying inactive slots. The TaskManager will free the slot if it does not become active within the given amount of time. Inactive slots can be caused by an out-dated slot request. If no value is configured, then it will fall back to akka.ask.timeout."
  },
  {
    "Key": "taskmanager.network.blocking-shuffle.compression.enabled",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Boolean flag indicating whether the shuffle data will be compressed for blocking shuffle mode. Note that data is compressed per buffer and compression can incur extra CPU overhead, so it is more effective for IO bounded scenario when compression ratio is high."
  },
  {
    "Key": "taskmanager.network.blocking-shuffle.type",
    "Default": "\"file\"",
    "Type": "String",
    "Description": "The blocking shuffle type, either \"mmap\" or \"file\". The \"auto\" means selecting the property type automatically based on system memory architecture (64 bit for mmap and 32 bit for file). Note that the memory usage of mmap is not accounted by configured memory limits, but some resource frameworks like yarn would track this memory usage and kill the container once memory exceeding some threshold. Also note that this option is experimental and might be changed future."
  },
  {
    "Key": "taskmanager.network.detailed-metrics",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Boolean flag to enable/disable more detailed metrics about inbound/outbound network queue lengths."
  },
  {
    "Key": "taskmanager.network.memory.buffers-per-channel",
    "Default": "2",
    "Type": "Integer",
    "Description": "Number of exclusive network buffers to use for each outgoing/incoming channel (subpartition/inputchannel) in the credit-based flow control model. It should be configured at least 2 for good performance. 1 buffer is for receiving in-flight data in the subpartition and 1 buffer is for parallel serialization."
  },
  {
    "Key": "taskmanager.network.memory.floating-buffers-per-gate",
    "Default": "8",
    "Type": "Integer",
    "Description": "Number of extra network buffers to use for each outgoing/incoming gate (result partition/input gate). In credit-based flow control mode, this indicates how many floating credits are shared among all the input channels. The floating buffers are distributed based on backlog (real-time output buffers in the subpartition) feedback, and can help relieve back-pressure caused by unbalanced data distribution among the subpartitions. This value should be increased in case of higher round trip times between nodes and/or larger number of machines in the cluster."
  },
  {
    "Key": "taskmanager.network.memory.max-buffers-per-channel",
    "Default": "10",
    "Type": "Integer",
    "Description": "Number of max buffers that can be used for each channel. If a channel exceeds the number of max buffers, it will make the task become unavailable, cause the back pressure and block the data processing. This might speed up checkpoint alignment by preventing excessive growth of the buffered in-flight data in case of data skew and high number of configured floating buffers. This limit is not strictly guaranteed, and can be ignored by things like flatMap operators, records spanning multiple buffers or single timer producing large amount of data."
  },
  {
    "Key": "taskmanager.network.netty.client.connectTimeoutSec",
    "Default": "120",
    "Type": "Integer",
    "Description": "The Netty client connection timeout."
  },
  {
    "Key": "taskmanager.network.netty.client.numThreads",
    "Default": "-1",
    "Type": "Integer",
    "Description": "The number of Netty client threads."
  },
  {
    "Key": "taskmanager.network.netty.num-arenas",
    "Default": "-1",
    "Type": "Integer",
    "Description": "The number of Netty arenas."
  },
  {
    "Key": "taskmanager.network.netty.sendReceiveBufferSize",
    "Default": "0",
    "Type": "Integer",
    "Description": "The Netty send and receive buffer size. This defaults to the system buffer size (cat /proc/sys/net/ipv4/tcp_[rw]mem) and is 4 MiB in modern Linux."
  },
  {
    "Key": "taskmanager.network.netty.server.backlog",
    "Default": "0",
    "Type": "Integer",
    "Description": "The netty server connection backlog."
  },
  {
    "Key": "taskmanager.network.netty.server.numThreads",
    "Default": "-1",
    "Type": "Integer",
    "Description": "The number of Netty server threads."
  },
  {
    "Key": "taskmanager.network.netty.transport",
    "Default": "\"auto\"",
    "Type": "String",
    "Description": "The Netty transport type, either \"nio\" or \"epoll\". The \"auto\" means selecting the property mode automatically based on the platform. Note that the \"epoll\" mode can get better performance, less GC and have more advanced features which are only available on modern Linux."
  },
  {
    "Key": "taskmanager.network.request-backoff.initial",
    "Default": "100",
    "Type": "Integer",
    "Description": "Minimum backoff in milliseconds for partition requests of input channels."
  },
  {
    "Key": "taskmanager.network.request-backoff.max",
    "Default": "10000",
    "Type": "Integer",
    "Description": "Maximum backoff in milliseconds for partition requests of input channels."
  },
  {
    "Key": "taskmanager.network.retries",
    "Default": "0",
    "Type": "Integer",
    "Description": "The number of retry attempts for network communication. Currently it\u0027s only used for establishing input/output channel connections"
  },
  {
    "Key": "taskmanager.network.sort-shuffle.min-buffers",
    "Default": "64",
    "Type": "Integer",
    "Description": "Minimum number of network buffers required per sort-merge blocking result partition. For production usage, it is suggested to increase this config value to at least 2048 (64M memory if the default 32K memory segment size is used) to improve the data compression ratio and reduce the small network packets. Usually, several hundreds of megabytes memory is enough for large scale batch jobs. Note: you may also need to increase the size of total network memory to avoid the \u0027insufficient number of network buffers\u0027 error if you are increasing this config value."
  },
  {
    "Key": "taskmanager.network.sort-shuffle.min-parallelism",
    "Default": "2147483647",
    "Type": "Integer",
    "Description": "Parallelism threshold to switch between sort-merge blocking shuffle and the default hash-based blocking shuffle, which means for batch jobs of small parallelism, the hash-based blocking shuffle will be used and for batch jobs of large parallelism, the sort-merge one will be used. Note: For production usage, if sort-merge blocking shuffle is enabled, you may also need to enable data compression by setting \u0027taskmanager.network.blocking-shuffle.compression.enabled\u0027 to true and tune \u0027taskmanager.network.sort-shuffle.min-buffers\u0027 and \u0027taskmanager.memory.framework.off-heap.batch-shuffle.size\u0027 for better performance."
  },
  {
    "Key": "akka.ask.callstack",
    "Default": "true",
    "Type": "Boolean",
    "Description": "If true, call stack for asynchronous asks are captured. That way, when an ask fails (for example times out), you get a proper exception, describing to the original method call and call site. Note that in case of having millions of concurrent RPC calls, this may add to the memory footprint."
  },
  {
    "Key": "akka.ask.timeout",
    "Default": "\"10 s\"",
    "Type": "String",
    "Description": "Timeout used for all futures and blocking Akka calls. If Flink fails due to timeouts then you should try to increase this value. Timeouts can be caused by slow machines or a congested network. The timeout value requires a time-unit specifier (ms/s/min/h/d)."
  },
  {
    "Key": "akka.client-socket-worker-pool.pool-size-factor",
    "Default": "1.0",
    "Type": "Double",
    "Description": "The pool size factor is used to determine thread pool size using the following formula: ceil(available processors * factor). Resulting size is then bounded by the pool-size-min and pool-size-max values."
  },
  {
    "Key": "akka.client-socket-worker-pool.pool-size-max",
    "Default": "2",
    "Type": "Integer",
    "Description": "Max number of threads to cap factor-based number to."
  },
  {
    "Key": "akka.client-socket-worker-pool.pool-size-min",
    "Default": "1",
    "Type": "Integer",
    "Description": "Min number of threads to cap factor-based number to."
  },
  {
    "Key": "akka.fork-join-executor.parallelism-factor",
    "Default": "2.0",
    "Type": "Double",
    "Description": "The parallelism factor is used to determine thread pool size using the following formula: ceil(available processors * factor). Resulting size is then bounded by the parallelism-min and parallelism-max values."
  },
  {
    "Key": "akka.fork-join-executor.parallelism-max",
    "Default": "64",
    "Type": "Integer",
    "Description": "Max number of threads to cap factor-based parallelism number to."
  },
  {
    "Key": "akka.fork-join-executor.parallelism-min",
    "Default": "8",
    "Type": "Integer",
    "Description": "Min number of threads to cap factor-based parallelism number to."
  },
  {
    "Key": "akka.framesize",
    "Default": "\"10485760b\"",
    "Type": "String",
    "Description": "Maximum size of messages which are sent between the JobManager and the TaskManagers. If Flink fails because messages exceed this limit, then you should increase it. The message size requires a size-unit specifier."
  },
  {
    "Key": "akka.jvm-exit-on-fatal-error",
    "Default": "true",
    "Type": "Boolean",
    "Description": "Exit JVM on fatal Akka errors."
  },
  {
    "Key": "akka.log.lifecycle.events",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Turns on the Akka’s remote logging of events. Set this value to \u0027true\u0027 in case of debugging."
  },
  {
    "Key": "akka.lookup.timeout",
    "Default": "\"10 s\"",
    "Type": "String",
    "Description": "Timeout used for the lookup of the JobManager. The timeout value has to contain a time-unit specifier (ms/s/min/h/d)."
  },
  {
    "Key": "akka.retry-gate-closed-for",
    "Default": "50",
    "Type": "Long",
    "Description": "Milliseconds a gate should be closed for after a remote connection was disconnected."
  },
  {
    "Key": "akka.server-socket-worker-pool.pool-size-factor",
    "Default": "1.0",
    "Type": "Double",
    "Description": "The pool size factor is used to determine thread pool size using the following formula: ceil(available processors * factor). Resulting size is then bounded by the pool-size-min and pool-size-max values."
  },
  {
    "Key": "akka.server-socket-worker-pool.pool-size-max",
    "Default": "2",
    "Type": "Integer",
    "Description": "Max number of threads to cap factor-based number to."
  },
  {
    "Key": "akka.server-socket-worker-pool.pool-size-min",
    "Default": "1",
    "Type": "Integer",
    "Description": "Min number of threads to cap factor-based number to."
  },
  {
    "Key": "akka.ssl.enabled",
    "Default": "true",
    "Type": "Boolean",
    "Description": "Turns on SSL for Akka’s remote communication. This is applicable only when the global ssl flag security.ssl.enabled is set to true."
  },
  {
    "Key": "akka.startup-timeout",
    "Default": "(none)",
    "Type": "String",
    "Description": "Timeout after which the startup of a remote component is considered being failed."
  },
  {
    "Key": "akka.tcp.timeout",
    "Default": "\"20 s\"",
    "Type": "String",
    "Description": "Timeout for all outbound connections. If you should experience problems with connecting to a TaskManager due to a slow network, you should increase this value."
  },
  {
    "Key": "akka.throughput",
    "Default": "15",
    "Type": "Integer",
    "Description": "Number of messages that are processed in a batch before returning the thread to the pool. Low values denote a fair scheduling whereas high values can increase the performance at the cost of unfairness."
  },
  {
    "Key": "env.hadoop.conf.dir",
    "Default": "(none)",
    "Type": "String",
    "Description": "Path to hadoop configuration directory. It is required to read HDFS and/or YARN configuration. You can also set it via environment variable."
  },
  {
    "Key": "env.hbase.conf.dir",
    "Default": "(none)",
    "Type": "String",
    "Description": "Path to hbase configuration directory. It is required to read HBASE configuration. You can also set it via environment variable."
  },
  {
    "Key": "env.java.opts",
    "Default": "(none)",
    "Type": "String",
    "Description": "Java options to start the JVM of all Flink processes with."
  },
  {
    "Key": "env.java.opts.client",
    "Default": "(none)",
    "Type": "String",
    "Description": "Java options to start the JVM of the Flink Client with."
  },
  {
    "Key": "env.java.opts.historyserver",
    "Default": "(none)",
    "Type": "String",
    "Description": "Java options to start the JVM of the HistoryServer with."
  },
  {
    "Key": "env.java.opts.jobmanager",
    "Default": "(none)",
    "Type": "String",
    "Description": "Java options to start the JVM of the JobManager with."
  },
  {
    "Key": "env.java.opts.taskmanager",
    "Default": "(none)",
    "Type": "String",
    "Description": "Java options to start the JVM of the TaskManager with."
  },
  {
    "Key": "env.log.dir",
    "Default": "(none)",
    "Type": "String",
    "Description": "Defines the directory where the Flink logs are saved. It has to be an absolute path. (Defaults to the log directory under Flink’s home)"
  },
  {
    "Key": "env.log.max",
    "Default": "5",
    "Type": "Integer",
    "Description": "The maximum number of old log files to keep."
  },
  {
    "Key": "env.pid.dir",
    "Default": "\"/tmp\"",
    "Type": "String",
    "Description": "Defines the directory where the flink-\u003chost\u003e-\u003cprocess\u003e.pid files are saved."
  },
  {
    "Key": "env.ssh.opts",
    "Default": "(none)",
    "Type": "String",
    "Description": "Additional command line options passed to SSH clients when starting or stopping JobManager, TaskManager, and Zookeeper services (start-cluster.sh, stop-cluster.sh, start-zookeeper-quorum.sh, stop-zookeeper-quorum.sh)."
  },
  {
    "Key": "env.yarn.conf.dir",
    "Default": "(none)",
    "Type": "String",
    "Description": "Path to yarn configuration directory. It is required to run flink on YARN. You can also set it via environment variable."
  },
  {
    "Key": "compiler.delimited-informat.max-line-samples",
    "Default": "10",
    "Type": "Integer",
    "Description": "The maximum number of line samples taken by the compiler for delimited inputs. The samples are used to estimate the number of records. This value can be overridden for a specific input with the input format’s parameters."
  },
  {
    "Key": "compiler.delimited-informat.max-sample-len",
    "Default": "2097152",
    "Type": "Integer",
    "Description": "The maximal length of a line sample that the compiler takes for delimited inputs. If the length of a single sample exceeds this value (possible because of misconfiguration of the parser), the sampling aborts. This value can be overridden for a specific input with the input format’s parameters."
  },
  {
    "Key": "compiler.delimited-informat.min-line-samples",
    "Default": "2",
    "Type": "Integer",
    "Description": "The minimum number of line samples taken by the compiler for delimited inputs. The samples are used to estimate the number of records. This value can be overridden for a specific input with the input format’s parameters"
  },
  {
    "Key": "taskmanager.runtime.hashjoin-bloom-filters",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Flag to activate/deactivate bloom filters in the hybrid hash join implementation. In cases where the hash join needs to spill to disk (datasets larger than the reserved fraction of memory), these bloom filters can greatly reduce the number of spilled records, at the cost some CPU cycles."
  },
  {
    "Key": "taskmanager.runtime.large-record-handler",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Whether to use the LargeRecordHandler when spilling. If a record will not fit into the sorting buffer. The record will be spilled on disk and the sorting will continue with only the key. The record itself will be read afterwards when merging."
  },
  {
    "Key": "taskmanager.runtime.max-fan",
    "Default": "128",
    "Type": "Integer",
    "Description": "The maximal fan-in for external merge joins and fan-out for spilling hash tables. Limits the number of file handles per operator, but may cause intermediate merging/partitioning, if set too small."
  },
  {
    "Key": "taskmanager.runtime.sort-spilling-threshold",
    "Default": "0.8",
    "Type": "Float",
    "Description": "A sort operation starts spilling when this fraction of its memory budget is full."
  },
  {
    "Key": "fs.output.always-create-directory",
    "Default": "false",
    "Type": "Boolean",
    "Description": "File writers running with a parallelism larger than one create a directory for the output file path and put the different result files (one per parallel writer task) into that directory. If this option is set to \"true\", writers with a parallelism of 1 will also create a directory and place a single result file into it. If the option is set to \"false\", the writer will directly create the file directly at the output path, without creating a containing directory."
  },
  {
    "Key": "fs.overwrite-files",
    "Default": "false",
    "Type": "Boolean",
    "Description": "Specifies whether file output writers should overwrite existing files by default. Set to \"true\" to overwrite by default,\"false\" otherwise."
  }
]
